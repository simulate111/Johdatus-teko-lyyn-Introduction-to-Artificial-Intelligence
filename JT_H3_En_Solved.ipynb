{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/Johdatus-teko-lyyn-Introduction-to-Artificial-Intelligence/blob/main/JT_H3_En_Solved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LuxZE9_DPTWX"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "JZKKODZJPTWY",
        "outputId": "6f090b89-315d-493a-e1be-a35df563d122"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
              "    return false;\n",
              "}\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%%javascript\n",
        "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
        "    return false;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UkHhF71XPTWa"
      },
      "outputs": [],
      "source": [
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, precision_recall_curve, roc_auc_score, auc\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from skimage.feature import hog\n",
        "from skimage import io\n",
        "from skimage.filters import threshold_sauvola\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import resize\n",
        "from scipy import ndimage\n",
        "from skimage import measure\n",
        "import matplotlib.patches as mpatches\n",
        "from imblearn.over_sampling import SVMSMOTE\n",
        "plt.rcParams['figure.figsize'] = (15, 6)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onedrivedownloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V5-FQSEPZ8y",
        "outputId": "5781e60c-429e-43d2-b16e-43f338488847"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onedrivedownloader\n",
            "  Downloading onedrivedownloader-1.1.3-py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from onedrivedownloader) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from onedrivedownloader) (4.66.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->onedrivedownloader) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->onedrivedownloader) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->onedrivedownloader) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->onedrivedownloader) (2024.2.2)\n",
            "Installing collected packages: onedrivedownloader\n",
            "Successfully installed onedrivedownloader-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQtDuEfWPTWc",
        "outputId": "8ad76d44-ea57-48df-9290-81cbaba5b53f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.91M/2.91M [00:02<00:00, 1.23MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting files: 100%|██████████| 15/15 [00:00<00:00, 441.88it/s]\n"
          ]
        }
      ],
      "source": [
        "from onedrivedownloader import download\n",
        "\n",
        "link2data = 'https://unioulu-my.sharepoint.com/:u:/g/personal/jukmaatt_univ_yo_oulu_fi/ET3iUnWprHVGqjKavqhFmz4BpCN4WGYrSovJNbIBzkD3JQ?e=SK1SlV'\n",
        "\n",
        "if not os.path.exists('./data'):\n",
        "    print('Downloading data')\n",
        "    download(link2data, filename='./files.zip', unzip=True, unzip_path='./')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWcBq71cPTWd"
      },
      "source": [
        "# <center>521160P Introduction to artificial intelligence<br><br>Exercise #3<br><br>Classification<br></center>\n",
        "\n",
        "This exercise validates the optimal values of hyperparameters for classifiers and compares the effect of balanced and unbalanced teaching data on classifier performance. **Look return deadlines from moodle**. (Return instructions for this exercise are sligthly different from previous ones). It is possible to get 4 points from this exercise (2.0p + 2.0p).\n",
        "\n",
        "If you have any questions related to exercises or you face any problems during this exercise please use moodle forum for **programming exercise 3**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDEMWguzPTWe"
      },
      "source": [
        "**First fill in your group information (name and student number)**\n",
        "\n",
        "# Group member information :\n",
        "\n",
        "* **Member 1 :** `...`\n",
        "* **Member 2 :** `...`\n",
        "* **Member 3 :** `... `"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1P3SHs6PTWf"
      },
      "source": [
        "# Task 1. Classifier validation and testing\n",
        "\n",
        "This task teaches three different classifiers to classify MNIST data, validate classifiers, and evaluate classifier performance. MNIST data contains handwritten numbers from 0 to 9. For each category, the data contains 7000 samples, i.e. it is balanced data. In total, the MNIST data contain 70,000 samples collected from U.S. Census staff and high school students. The data samples are scaled to 20x20 pixel grayscale images and finally centered on a 28x28 pixel grid. The classification accuracies of simple classifiers taught with this data range between 80% and 99%. Figure 1 shows sample samples of ten classes of MNIST data.\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "<div style=\"width:image width px; font-size:80%; text-align:center;\">\n",
        "    <center>\n",
        "    <img src='https://github.com/simulate111/Johdatus-teko-lyyn-Introduction-to-Artificial-Intelligence/blob/main/imgs/mnist.png?raw=1' width='650' height='auto' style='padding-bottom:0.5em;' />\n",
        "    </center>\n",
        "    <span>Figure 1. Sample images of ten classes of MNIST data.</span>\n",
        "</div>\n",
        "<br>\n",
        "\n",
        "Data samples are not fed directly to the classification algorithms, but image preprocessing achieves a better result. HOG (histogram of oriented gradients) is chosen as the data preprocessing method.\n",
        "\n",
        "The HOG method calculates a feature vector for an image that is nearly identical to the same image with different contrast values. Initially, the method divides the input image into blocks. For each pixel in the block, a gradient is calculated that tells you the direction and magnitude of the darkening of the image. By placing the gradients of the block in the histogram, the HOG features of the block are obtained. Figure 2 calculates the HOG features for the MNIST data sample and finally visualizes them in the initial image. The input image is divided into 16 blocks and gradients are thresholded every 40 degrees.\n",
        "\n",
        "<br>\n",
        "<div style=\"width:image width px; font-size:80%; text-align:center;\">\n",
        "    <center>\n",
        "    <img src='https://github.com/simulate111/Johdatus-teko-lyyn-Introduction-to-Artificial-Intelligence/blob/main/imgs/hog.png?raw=1' width='750' height='auto' style='padding-bottom:0.5em;' />\n",
        "    </center>\n",
        "    <span>Figure 2. HOG features for the MNIST data sample.</span>\n",
        "</div>\n",
        "<br>\n",
        "\n",
        "Use 10,000 samples instead of the original 70,000 samples in this task. Divide the calculated HOG features by the [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function of the scikit-learn library with teaching, validation and test data in an 80:10:10 division ratio. After distribution, there are 8000 samples in the teaching data, 1000 samples in the validation data and 1000 samples in the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uIzKiZ7PTWf"
      },
      "outputs": [],
      "source": [
        "# Load MNIST data. Data includes 784 variables (28x28 grayscale) and data's class information.\n",
        "data, classes = datasets.fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "data, classes = np.asarray(data, 'int16'), np.asarray(classes, 'int')\n",
        "data, classes = data[:10000], classes[:10000]\n",
        "\n",
        "# For Images calculate HOG-features\n",
        "features = []\n",
        "for sample in data:\n",
        "    features.append(hog(sample.reshape((28, 28)), orientations=9, pixels_per_cell=(7, 7), cells_per_block=(1, 1), block_norm=\"L2-Hys\", visualize=False))\n",
        "\n",
        "# Divide features into teaching data, validation data and test data in two stages\n",
        "data_teaching, data_tmp, classes_teaching, classes_tmp = train_test_split(features, classes, test_size=(1/5), random_state=0)\n",
        "data_test, data_validate, classes_test, classes_validate = train_test_split(data_tmp, classes_tmp, test_size=(1/2), random_state=0)\n",
        "\n",
        "# Print teaching data, validation data and test data sample ammount\n",
        "print('teaching data has {} samples'.format(classes_teaching.shape[0]))\n",
        "print('validate data has {} samples'.format(classes_validate.shape[0]))\n",
        "print('test data has {} samples'.format(classes_test.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lP_t-3zPTWg"
      },
      "source": [
        "Next, validation data is used to find optimal hyperparameter values for the k-nearest Neighbors (k-NN), linear support vector machines (linear SVM), and logistic regression.\n",
        "\n",
        "## Validating k-nearest neigbors classifier\n",
        "\n",
        "Start validation on the number of neighbors $ k $ of the [k-nearest neighbor classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier). Let's go through the loop $ k $ values 1-33 every four steps. Then the effect of the value of $ k $ on the classification accuracy is plotted on the graph and the best value of $ k $ is selected from the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkDlxwMPPTWg"
      },
      "outputs": [],
      "source": [
        "# Perform validation of k-nearest neighbour classifier\n",
        "\n",
        "# Loop through values from 1 to 33 with steps of 4\n",
        "classification_accuracy_knn = []\n",
        "k_values = range(1,34,4)\n",
        "for k in k_values:\n",
        "    classifier_knn = KNeighborsClassifier(n_neighbors=k).fit(data_teaching, classes_teaching)\n",
        "    classification_accuracy_knn.append(accuracy_score(classes_validate, classifier_knn.predict(data_validate)))\n",
        "\n",
        "# Plot a graph with different k values to see how it affects classification accuracy\n",
        "plt.plot(k_values, classification_accuracy_knn)\n",
        "plt.title('k-nearest neighbour classifier classification accuracy with different k values')\n",
        "plt.xlabel('k value')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Finally choose best k value from graph\n",
        "maximum_index_knn = np.argmax(classification_accuracy_knn)\n",
        "print('Best value k value for k-nearest neighbour classifier: {}'.format(k_values[maximum_index_knn]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXyGL6QLPTWg"
      },
      "source": [
        "## Validation of a linear support vector machine\n",
        "\n",
        "The support vector machine tries to match the decision level between the classes so that the margin between the classes is as large as possible. For a linear support vector machine, the most important value of the hyperparameter is $C$. Its magnitude indicates how much is avoided from misclassifying samples of teaching data. Large values of $C$ can emphasize a smaller choice of marginal decision levels if they lead to a better classification result for teaching data. Small values of $C$, in turn, emphasize the choice of higher margin decision levels at the expense of the teaching data classification result.\n",
        "\n",
        "Next, validate the value of the hyperparameter $C$ of the [linear support vector machine](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html). Let's loop through the $C$ values $10 ^{n}$, where $n$ is -5, -4, ..., 14, 15. Then plot the effect of the exponent value of $ $ on the classification accuracy and select the best value of $C$ from the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "9vE_FmFsPTWh"
      },
      "outputs": [],
      "source": [
        "# Perform validation of linear support vector machine\n",
        "# Loop through exponent values of C -5 to 15\n",
        "classification_accuracy_linear_svm = []\n",
        "n1 = np.array(range(-5,16),dtype=float)\n",
        "C1_values = 10**n1\n",
        "for C1 in C1_values:\n",
        "    classifier_linear_svm = LinearSVC(C=C1, random_state=0).fit(data_teaching, classes_teaching)\n",
        "    classification_accuracy_linear_svm.append(accuracy_score(classes_validate, classifier_linear_svm.predict(data_validate)))\n",
        "\n",
        "# Plot a graph with different exponents of C to see how it affects classification accuracy\n",
        "plt.plot(n1, classification_accuracy_linear_svm)\n",
        "plt.title('Linear support vector machine classification accuracy with different exponents of C')\n",
        "plt.xlabel('C\\'s exponent value n')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Finally choose best C value from graph\n",
        "maximum_index_linear_svm = np.argmax(classification_accuracy_linear_svm)\n",
        "print('Best C value for linear support vector machine: 10^({})'.format(n1[maximum_index_linear_svm]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQ6XB93VPTWh"
      },
      "source": [
        "## Validation of logistic regression classifier\n",
        "Finally validate [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) using hyperparameter $C$. It regulates the intensity of the regularization of the classifier. Let's loop through $C$ values $10^{n}$, where $n$ is -5, -4, ..., 14, 15. Then plot the effect of the exponent value of $C$ on the classification accuracy and select the best value of $C$ from the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vmej71UhPTWh"
      },
      "outputs": [],
      "source": [
        "# Perform validation of logistic regression\n",
        "# Loop through exponent values of C from -5 to 15\n",
        "classification_accuracy_logistic_regression = []\n",
        "n2 = np.array(range(-5,16),dtype=float)\n",
        "C2_values = 10**n2\n",
        "for C2 in C2_values:\n",
        "    classifier_logistic_regression = LogisticRegression(C=C2, solver='sag', random_state=0).fit(data_teaching, classes_teaching)\n",
        "    classification_accuracy_logistic_regression.append(accuracy_score(classes_validate, classifier_logistic_regression.predict(data_validate)))\n",
        "\n",
        "# Plot a graph with different exponents of C to see how it affects classification accuracy\n",
        "plt.plot(n2, classification_accuracy_logistic_regression)\n",
        "plt.title('Logistic regression machine classification accuracy with different exponents of C')\n",
        "plt.xlabel('C\\'s exponent value n')\n",
        "plt.ylabel('Classification accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Finally choose best C value from graph\n",
        "maximum_index_logistic_regression = np.argmax(classification_accuracy_logistic_regression)\n",
        "print('Best C value for logistic regression: 10^({})'.format(n2[maximum_index_logistic_regression]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URDxbHUDPTWi"
      },
      "source": [
        "Once the best values of the classifiers hyperparameters have been determined, extract them and teach them using the final classifiers. Thus, you should give the best value of $k$ to the classifier of the k-nearest neighbor, the best exponent of $C$ for a linear support vector machine, and the best exponent of $C$ for logistic regression $n_2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKd-pmF-PTWi"
      },
      "outputs": [],
      "source": [
        "# Teach classifier with best k, n and n2 values\n",
        "#-------- Your code here --------\n",
        "k =\n",
        "n1 =\n",
        "n2 =\n",
        "#-----------------------------------\n",
        "\n",
        "classifier_knn_validate = KNeighborsClassifier(n_neighbors=k).fit(data_teaching, classes_teaching)\n",
        "classifier_linear_svm_validate = LinearSVC(C=10**(n1), random_state=0).fit(data_teaching, classes_teaching)\n",
        "classifier_logistic_regression_validate = LogisticRegression(C=10**(n2), solver='sag', random_state=0).fit(data_teaching, classes_teaching)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Djvs1gymPTWi"
      },
      "source": [
        "Next, the performance of classifiers is evaluated based on confusion matrices and classification accuracies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGoTTicHPTWi"
      },
      "outputs": [],
      "source": [
        "def print_confusion_matrix(conf_matrix, title):\n",
        "    \"\"\"\n",
        "    This function prints confusion matrix\n",
        "    \"\"\"\n",
        "    normalized_values = []\n",
        "    for row in conf_matrix:\n",
        "        summ = 0\n",
        "        values = []\n",
        "        summ = sum(row, 0)\n",
        "        for value in row:\n",
        "            values.append(float(value)/float(summ))\n",
        "        normalized_values.append(values)\n",
        "    fig = plt.figure()\n",
        "    plt.clf()\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.set_aspect(1)\n",
        "    colors = ax.imshow(np.array(normalized_values), cmap=plt.cm.Blues, interpolation='nearest')\n",
        "    width, height = conf_matrix.shape\n",
        "    for i in range(width):\n",
        "        for j in range(height):\n",
        "            ax.annotate(str(conf_matrix[i][j]), xy=(j, i), horizontalalignment='center', verticalalignment=\"center\")\n",
        "    fig.colorbar(colors)\n",
        "    classes = '0123456789'\n",
        "    plt.xticks(range(width), classes[:width])\n",
        "    plt.yticks(range(height), classes[:height])\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predicted classes\")\n",
        "    plt.ylabel(\"Correct classes\")\n",
        "\n",
        "# Predict classes with validated k-nearest neighbour, place predicted classes in confusion matrix and calculate classification accuracy\n",
        "classes_predicted_knn = classifier_knn_validate.predict(data_test)\n",
        "print_confusion_matrix(confusion_matrix(classes_test, classes_predicted_knn), 'confusion_matrix for k-nearest neighbour classifier')\n",
        "print('Classification accuracy for k-nearest neighbour: {} %'.format(round(100*accuracy_score(classes_test, classes_predicted_knn),3)))\n",
        "\n",
        "# Predict classes with validated linear support vector machine, place predicted classes in confusion matrix and calculate classification accuracy\n",
        "classes_predicted_linear_svm = classifier_linear_svm_validate.predict(data_test)\n",
        "print_confusion_matrix(confusion_matrix(classes_test, classes_predicted_linear_svm), 'confusion matrix for linear support vector machine')\n",
        "print('Classification accuracy for linear support vector machine: {} %'.format(round(100*accuracy_score(classes_test, classes_predicted_linear_svm),3)))\n",
        "\n",
        "# Predict classes with validated logistic regression, place predicted classes in confusion matrix and calculate classification accuracy\n",
        "classes_predicted_logistic_regression = classifier_logistic_regression_validate.predict(data_test)\n",
        "print_confusion_matrix(confusion_matrix(classes_test, classes_predicted_logistic_regression), 'confusion matrix for logistic regression')\n",
        "print('Classification accuracy for logistic regression: {} %'.format(round(100*accuracy_score(classes_test, classes_predicted_logistic_regression),3)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl1W0U8GPTWj"
      },
      "source": [
        "**Which of the validated classifiers is the best in terms of classification accuracy? By interpreting confusion_matrix, in which category (ies) does the classifier of the k-nearest neighbor most often confuse the handwritten number 4?**\n",
        "\n",
        "`Your answer here`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ETITmgBPTWj"
      },
      "source": [
        "Finally test how well validated k-nearest neighbour classifier performs for three test images. The handwritten numbers are segmented from the image by Sauvola's binarization method, after which red rectangles are drawn around the numbers. Finally, a validated k-nearest neighbor classifier is used to identify handwritten numbers in the images. The projections are drawn in the figure with red numbers below the rectangles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "CTwg-ifmPTWj"
      },
      "outputs": [],
      "source": [
        "def recognize_number_and_classify(img, classifier):\n",
        "    \"\"\"\n",
        "    This function recognizes handwritten numbers in an image,\n",
        "    calculates HOG features for them, and classifies them based on features\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Filter image\n",
        "    grayscale_img = rgb2gray(img)\n",
        "    threshold = threshold_sauvola(grayscale_img, window_size=155)\n",
        "    binarization_sauvola = grayscale_img > threshold\n",
        "    filtered_img = ndimage.median_filter(binarization_sauvola, size=15)\n",
        "\n",
        "    # Find rectangles\n",
        "    outlines = measure.find_contours(filtered_img, 0)\n",
        "    rectangles = []\n",
        "    offset = 25\n",
        "    for outline in outlines:\n",
        "        # xmin, xmax, ymin, ymax\n",
        "        rectangles.append([int(np.min(outline[:,0])-offset), int(np.max(outline[:,0])+offset), int(np.min(outline[:,1])-offset), int(np.max(outline[:,1])+offset)])\n",
        "\n",
        "    # Delete rectangles which are nested and leave out of the outermost rectangle\n",
        "    removable_indices  = []\n",
        "    for i in range(len(rectangles)):\n",
        "        rectangle1 = rectangles[i]\n",
        "        rectangle1_ala = (rectangle1[1]-rectangle1[0])*(rectangle1[3]-rectangle1[2])\n",
        "        for j in range(len(rectangles)):\n",
        "            if i >= j:\n",
        "                continue\n",
        "            rectangle2 = rectangles[j]\n",
        "            rectangle2_ala = (rectangle2[1]-rectangle2[0])*(rectangle2[3]-rectangle2[2])\n",
        "            if (rectangle2[0]>rectangle1[0] and rectangle2[0]<rectangle1[1]) and (rectangle2[2]>rectangle1[2] and rectangle2[2]<rectangle1[3]):\n",
        "                if rectangle1_ala >= rectangle2_ala:\n",
        "                    removable_indices .append(j)\n",
        "                else:\n",
        "                    removable_indices .append(i)\n",
        "    rectangles = [i for j, i in enumerate(rectangles) if j not in removable_indices ]\n",
        "\n",
        "    # Segment the image and calculate HOG features for the segmented areas\n",
        "    # Finally, a classifier is used to identify handwritten numbers in the image\n",
        "    plt.imshow(img)\n",
        "    for rectangle in rectangles:\n",
        "        restricted_area = grayscale_img[rectangle[0]:rectangle[1],rectangle[2]:rectangle[3]]\n",
        "        restricted_area = resize(restricted_area, (28,28), order=0)\n",
        "        restricted_area = np.asarray(minmax_scale(restricted_area.ravel(), feature_range=(0, 255)), dtype=int).reshape((28,28))\n",
        "        restricted_area[restricted_area>220] = 255\n",
        "        hog_features = [hog(restricted_area, orientations=9, pixels_per_cell=(7, 7), cells_per_block=(1, 1), block_norm=\"L2-Hys\",visualize=False)]\n",
        "        prediction = classifier.predict(hog_features)\n",
        "        plt.text(rectangle[2] + (rectangle[3]-rectangle[2])//2 - 15, rectangle[1] + (1.5*offset), str(int(prediction.item())), color='r')\n",
        "    ax = plt.gca()\n",
        "    for rectangle in rectangles:\n",
        "        xmin, xmax, ymin, ymax = rectangle[0], rectangle[1], rectangle[2], rectangle[3]\n",
        "        rectangle_drawing = mpatches.Rectangle((ymin, xmin), ymax - ymin, xmax - xmin,fill=False, edgecolor='red', linewidth=2)\n",
        "        ax.add_patch(rectangle_drawing)\n",
        "\n",
        "# Load test images\n",
        "img1 = io.imread('data/kuva1.jpg')\n",
        "img2 = io.imread('data/kuva2.jpg')\n",
        "img3 = io.imread('data/kuva3.jpg')\n",
        "\n",
        "# Recognize handwritten numbers from test images\n",
        "recognize_number_and_classify(img1, classifier_knn_validate)\n",
        "recognize_number_and_classify(img2, classifier_knn_validate)\n",
        "recognize_number_and_classify(img3, classifier_knn_validate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI0kyfRaPTWj"
      },
      "source": [
        "Täytä lopuksi confusion_matrix vastaamaan kolmen testikuvan luokittelutulosta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSYLcNhPPTWk"
      },
      "outputs": [],
      "source": [
        "# Fill in the confusion matrix to match the classification result of the three test images\n",
        "#-------- Your code here --------\n",
        "confusion_matrix1 = [[8,0,0,0,0,0,0,0,0,0],\n",
        "                     [0,8,0,0,0,0,0,0,0,0],\n",
        "                     [0,0,8,0,0,0,0,0,0,0],\n",
        "                     [0,0,0,8,0,0,0,0,0,0],\n",
        "                     [0,0,0,0,8,0,0,0,0,0],\n",
        "                     [0,0,0,0,0,8,0,0,0,0],\n",
        "                     [0,0,0,0,0,0,8,0,0,0],\n",
        "                     [0,0,0,0,0,0,0,8,0,0],\n",
        "                     [0,0,0,0,0,0,0,0,8,0],\n",
        "                     [0,0,0,0,0,0,0,0,0,8]]\n",
        "#-----------------------------------\n",
        "\n",
        "print_confusion_matrix(np.array(confusion_matrix1), 'confusion matrix for test images with k-nearest neighbour')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlL8EylEPTWk"
      },
      "source": [
        "# Task 2. The effect of balanced and unbalanced teaching data on classifier performance\n",
        "\n",
        "The second task compares the difference in performance between classifiers taught with balanced and unbalanced data. Many real-life data are unbalanced, with few samples of the phenomenon of interest compared to other categories of data. If the data imbalance is ignored when teaching and testing the classifier, it can have a negative impact on the classifier’s performance and form a false picture of its performance.\n",
        "\n",
        "Satellite images such as Figure 3 from the sea surface, converted to numerical features, are used as data to detect oil spills. The decoupling of satellite imagery features has been accomplished using digital image processing techniques. The modified 49 features describe e.g. the location of the center of the potential oil spill area in the image, the shape of the area, the area, the intensity, and the roughness of the edge.\n",
        "\n",
        "A total of 937 samples are included in the data, of which 896 belong to category -1 (no oil leakage) and 41 to category 1 (oil leakage). Divide the data by a ratio of 80:20 into teaching data and test data. The imbalance between teaching data and test data is illustrated by bar graphs. Random forest, logistic regression, and the k-closest neighbor classifier are used as classifiers to solve the problem, the values of the hyperparameters of which are already known in advance and do not need to be validated separately.\n",
        "\n",
        "<br>\n",
        "<div style=\"width:image width px; font-size:80%; text-align:center;\">\n",
        "    <center>\n",
        "    <img src='https://github.com/simulate111/Johdatus-teko-lyyn-Introduction-to-Artificial-Intelligence/blob/main/imgs/oil_spill.jpg?raw=1' width='550' height='auto' style='padding-bottom:0.5em;' />\n",
        "    </center>\n",
        "    <span>Figure 3. Satellite image of sea level to identify oil spills.</span>\n",
        "</div>\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjxTmBrtPTWk"
      },
      "outputs": [],
      "source": [
        "# Loading oil leak data. The variable data2 contains 49 features and the variable classes2 class information\n",
        "data2, classes2 = datasets.fetch_openml('oil_spill', return_X_y=True)\n",
        "classes2 = np.asarray(classes2, 'int')\n",
        "\n",
        "# The features are divided into teaching data and test data\n",
        "data2_teaching, data2_test, classes2_teaching, classes2_test = train_test_split(data2, classes2, test_size=(1/5), random_state=0)\n",
        "\n",
        "# Illustrate the imbalance of teaching data with a bar chart\n",
        "plt.subplot(121)\n",
        "categories_teaching, quantities_teaching = np.unique(classes2_teaching.astype('U'), return_counts=True)\n",
        "plt.bar(categories_teaching, quantities_teaching, color=['red','green'])\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of teaching samples')\n",
        "plt.title('Number of teaching samples per class for oil spill data')\n",
        "\n",
        "# Illustrate the imbalance of test data with a bar chart\n",
        "plt.subplot(122)\n",
        "categories_test, quantities_test = np.unique(classes2_test.astype('U'), return_counts=True)\n",
        "plt.bar(categories_test, quantities_test, color=['red','green'])\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of test samples')\n",
        "plt.title('Number of teaching samples per class for oil spill data')\n",
        "plt.show()\n",
        "\n",
        "# Print the numbers of samples of teaching data and test data per category\n",
        "print('Teaching data class {} has {} samples and in class {} there is {} samples'.format(categories_teaching[0], quantities_teaching[0], categories_teaching[1], quantities_teaching[1]))\n",
        "print('Test data class {} has {} samples and in class {} there is {} samples'.format(categories_test[0], quantities_test[0], categories_test[1], quantities_test[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPvcOiUTPTWl"
      },
      "source": [
        "When the data is strongly unbalanced, the classification accuracy does not give a true picture of the classifier’s performance. Often, classifiers learn to identify majority-class samples well, but identification of minority-class samples of interest is poor. For example, if the classifier identified all samples of the oil leakage classification problem test data as class -1, a classification accuracy of 94.7% would be achieved, even though no classification has actually occurred. This phenomenon is called the classification accuracy paradox. For this reason, instead of classification accuracy, measures such as sensitivity/recall/true positive rate and positive predictive value/accuracy are used for unbalanced data to assess how well the classifier actually performs the classification.\n",
        "\n",
        "Evaluate the performance of taught classifiers from the confusion matrices of test data for a binary two-class classification problem. We compare performance measures of classification accuracy, sensitivity, positive predictive value, and F1 score, which are calculated by the following equations.\n",
        "\n",
        "<br><br>\n",
        "\\begin{equation}\n",
        "\\text{classification accuracy} = \\frac{TP+TN}{P+N} = \\frac{TP+TN}{TP+FN+TN+FP}\n",
        "\\end{equation}\n",
        "\n",
        "<br><br>\n",
        "\\begin{equation}\n",
        "\\text{recall} = \\frac{TP}{P} = \\frac{TP}{TP+FN}\n",
        "\\end{equation}\n",
        "\n",
        "<br><br>\n",
        "\\begin{equation}\n",
        "\\text{precision} = \\frac{TP}{TP+FP}\n",
        "\\end{equation}\n",
        "\n",
        "<br><br>\n",
        "\\begin{equation}\n",
        "\\text{F1 score} = \\frac{2 \\cdot \\text{recall} \\cdot \\text{precision}}{\\text{recall}+\\text{precision}}\n",
        "\\end{equation}\n",
        "<br><br>\n",
        "\n",
        "The F1 value is the harmonic mean of the sensitivity and the positive predictive value. Implement the performance dimensions of the equations.\n",
        "\n",
        "After completing the measurements, check again with the oil spill-taught random forest that you get the correct values using sckit-learn library functions [metrics.accuracy_score()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html), [metrics.recall_score()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html), [metrics.precision_score()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html) and [metrics.f1_score()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyze2uftPTWl"
      },
      "outputs": [],
      "source": [
        "def calculate_classification_accuracy(confusion_matrix):\n",
        "    \"\"\"\n",
        "    This function calculates classification accuracy from 2x2 confusion matrixsta\n",
        "    \"\"\"\n",
        "    TN, FP, FN, TP = confusion_matrix.ravel()\n",
        "    #-------- Your code here --------\n",
        "    # Calculate accuracy\n",
        "\n",
        "    # Function returns accuracy\n",
        "\n",
        "    #-----------------------------------\n",
        "\n",
        "def calculate_recall(confusion_matrix):\n",
        "    \"\"\"\n",
        "    This function calculates recall from 2x2 confusion_matrixsta\n",
        "    \"\"\"\n",
        "    TN, FP, FN, TP = confusion_matrix.ravel()\n",
        "    #-------- Your code here --------\n",
        "    # Calculate recall\n",
        "\n",
        "    # Function returns recall\n",
        "\n",
        "    #-----------------------------------\n",
        "\n",
        "def calculate_precision(confusion_matrix):\n",
        "    \"\"\"\n",
        "    This function calculates precision from 2x2 confusion_matrixsta\n",
        "    \"\"\"\n",
        "    TN, FP, FN, TP = confusion_matrix.ravel()\n",
        "    #-------- Your code here --------\n",
        "    # Calculate precision\n",
        "\n",
        "    # Function returns precision\n",
        "\n",
        "    #-----------------------------------\n",
        "\n",
        "def calculate_f1_score(recall, precision):\n",
        "    \"\"\"\n",
        "    This function calculates F1 score from recall and precision\n",
        "    \"\"\"\n",
        "    #-------- Your code here --------\n",
        "    # Calculate F1 score\n",
        "\n",
        "    # Function returns F1-score\n",
        "\n",
        "    #-----------------------------------\n",
        "\n",
        "# Teach random forest and place predicted values of test data into confusion matrix\n",
        "classifier2_random_forest = RandomForestClassifier(n_estimators=100, random_state=0).fit(data2_teaching, classes2_teaching)\n",
        "confusion_matrix2_random_forest = confusion_matrix(classes2_test,classifier2_random_forest.predict(data2_test))\n",
        "\n",
        "print('Classification accuracy for random forest with ready-made function in scikit-learn library: {}'.format(accuracy_score(classes2_test, classifier2_random_forest.predict(data2_test))))\n",
        "print('Recall for random forest with ready-made function in scikit-learn library: {}'.format(recall_score(classes2_test, classifier2_random_forest.predict(data2_test))))\n",
        "print('Precision for random forest with ready-made function in scikit-learn library: {}'.format(precision_score(classes2_test, classifier2_random_forest.predict(data2_test))))\n",
        "print('F1 score for random forest with ready-made function in scikit-learn library: {}'.format(f1_score(classes2_test, classifier2_random_forest.predict(data2_test))))\n",
        "\n",
        "print('\\nClassification accuracy for random forest with function made by you: {}'.format(calculate_classification_accuracy(confusion_matrix2_random_forest)))\n",
        "print('Recall for random forest with function made by you: {}'.format(calculate_recall(confusion_matrix2_random_forest)))\n",
        "print('Precision for random forest with function made by you: {}'.format(calculate_precision(confusion_matrix2_random_forest)))\n",
        "print('F1 score for random forest with function made by you:: {}'.format(calculate_f1_score(calculate_recall(confusion_matrix2_random_forest), calculate_precision(confusion_matrix2_random_forest))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwvBntsvPTWl"
      },
      "source": [
        "In addition, logistic regression and the k-nearest neighbor classifier are taught with teaching samples of unbalanced oil spill data. Plot ROC curves for all three classifiers on the graph and calculate the corresponding ROC AUC values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTEp-e_0PTWl"
      },
      "outputs": [],
      "source": [
        "# Teaching logistic regression and k-nearest neighbor classifier with oil spill data teaching samples\n",
        "classifier2_logistic_regression = LogisticRegression(C=50, solver='liblinear', random_state=0).fit(data2_teaching, classes2_teaching)\n",
        "classifier2_knn = KNeighborsClassifier(n_neighbors=35).fit(data2_teaching, classes2_teaching)\n",
        "\n",
        "# Calculate the posterior probabilities of the test data\n",
        "posterior_probablity_random_forest = classifier2_random_forest.predict_proba(data2_test)[:, 1]\n",
        "posterior_probablity_logistic_regression = classifier2_logistic_regression.predict_proba(data2_test)[:, 1]\n",
        "posterior_probablity_knn = classifier2_knn.predict_proba(data2_test)[:, 1]\n",
        "\n",
        "# Calculate ROC-curves\n",
        "fpr_random_forest, tpr_random_forest, _ = roc_curve(classes2_test, posterior_probablity_random_forest)\n",
        "fpr_logistic_regression, tpr_logistic_regression, _ = roc_curve(classes2_test, posterior_probablity_logistic_regression)\n",
        "fpr_knn, tpr_knn, _ = roc_curve(classes2_test, posterior_probablity_knn)\n",
        "\n",
        "# Draw the ROC curves of all three classifiers on the graph\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(fpr_random_forest, tpr_random_forest, label='Random forest')\n",
        "plt.plot(fpr_logistic_regression, tpr_logistic_regression, label='Logistic regression')\n",
        "plt.plot(fpr_knn, tpr_knn, label='k-nearest neigbour classifier')\n",
        "plt.xlabel('1-Specifity')\n",
        "plt.ylabel('Recall')\n",
        "plt.title('ROC curves for classifiers taught with unbalanced teaching data')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Print ROC AUC values corresponding the ROC curves\n",
        "print('Random forest ROC AUC value: {}'.format(round(roc_auc_score(classes2_test, posterior_probablity_random_forest),3)))\n",
        "print('Logistic regression ROC AUC value: {}'.format(round(roc_auc_score(classes2_test, posterior_probablity_logistic_regression),3)))\n",
        "print('k-nearest neigbour  ROC AUC value: {}'.format(round(roc_auc_score(classes2_test, posterior_probablity_knn),3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfoDE8unPTWm"
      },
      "source": [
        "Plot a precision - recall curves for the classifiers and calculate the corresponding PR AUC values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJ0amdwaPTWm"
      },
      "outputs": [],
      "source": [
        "# Calculate PR curves\n",
        "precision_values_random_forest, recalls_random_forest, _ = precision_recall_curve(classes2_test, posterior_probablity_random_forest)\n",
        "precision_values_logistic_regression, recalls_logistic_regression, _ = precision_recall_curve(classes2_test, posterior_probablity_logistic_regression)\n",
        "precision_values_knn, recalls_knn, _ = precision_recall_curve(classes2_test, posterior_probablity_knn)\n",
        "\n",
        "# Draw the PR curves of all three classifiers on the graph\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(recalls_random_forest, precision_values_random_forest, label='Random forest')\n",
        "plt.plot(recalls_logistic_regression, precision_values_logistic_regression, label='Logistic regression')\n",
        "plt.plot(recalls_knn, precision_values_knn, label='k-nearest neigbour classifier')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision - recall curves for classifiers taught with unbalanced teaching data ')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Print PR AUC values corresponding to PR curves\n",
        "print('Random forest PR AUC value: {}'.format(round(auc(recalls_random_forest, precision_values_random_forest),3)))\n",
        "print('Logistic regression PR AUC value: {}'.format(round(auc(recalls_logistic_regression, precision_values_logistic_regression),3)))\n",
        "print('k-nearest neigbour classifier PR AUC value: {}'.format(round(auc(recalls_knn, precision_values_knn),3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po4FUwApPTWn"
      },
      "source": [
        "Finally, all measurement values describing the performance of the classifiers are calculated and presented in a table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFH8DjHvPTWn"
      },
      "outputs": [],
      "source": [
        "def calculate_measurement_values(data_test, classes_test, classifier, classifier_name):\n",
        "    \"\"\"\n",
        "    This function calculates measurement values of classifier and saves them to list\n",
        "    \"\"\"\n",
        "    # Calculate accuracy, recall, precision, F1 score, ROC AUC value ja PR AUC value\n",
        "    accuracy = round(accuracy_score(classes_test, classifier.predict(data_test)),3)\n",
        "    recall = round(recall_score(classes_test, classifier.predict(data_test)),3)\n",
        "    precision = round(precision_score(classes_test, classifier.predict(data_test)),3)\n",
        "    f1_arvo = round(f1_score(classes_test, classifier.predict(data_test)),3)\n",
        "    roc_auc = round(roc_auc_score(classes_test, classifier.predict_proba(data_test)[:, 1]),3)\n",
        "    precision_values, recalls, _ = precision_recall_curve(classes_test, classifier.predict_proba(data_test)[:, 1])\n",
        "    pr_auc = round(auc(recalls, precision_values),3)\n",
        "    return [classifier_name, accuracy, recall, precision, f1_arvo, roc_auc, pr_auc]\n",
        "\n",
        "# A table is made to show the performance measurements\n",
        "measurement_values = []\n",
        "measurement_values.append(['','$\\\\bf{Accuracy}$','$\\\\bf{Recall}$','$\\\\bf{Positive}$\\n $\\\\bf{predictive value}$','$\\\\bf{F1 score}$','$\\\\bf{ROC\\\\ AUC}$','$\\\\bf{PR\\\\ AUC}$'])\n",
        "measurement_values.append(calculate_measurement_values(data2_test, classes2_test, classifier2_random_forest, '$\\\\bf{Random forest}$'))\n",
        "measurement_values.append(calculate_measurement_values(data2_test, classes2_test, classifier2_logistic_regression, '$\\\\bf{Logistic\\\\ regression}$'))\n",
        "measurement_values.append(calculate_measurement_values(data2_test, classes2_test, classifier2_knn, '$\\\\bf{k-nearest}$\\n $\\\\bf{neighbour\\\\ classifier}$'))\n",
        "\n",
        "# print table\n",
        "table = plt.gca().table(cellText=measurement_values, loc='center', cellLoc='center')\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(9)\n",
        "table.scale(1,3)\n",
        "plt.gca().axis('off')\n",
        "plt.title('Performance metrics for classifiers taught with teaching samples of unbalanced oil spill data')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQcbkgTXPTWo"
      },
      "source": [
        "**List the classifiers in order of priority based on performance measures, ROC curves, and precision - recall curves.**\n",
        "\n",
        "`Your answer here`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS-_Zr8WPTWo"
      },
      "source": [
        "## Oversampling of teaching data\n",
        "\n",
        "Oversampling the training data with the SVMSMOTE algorithm to improve the performance of the classifiers. Illustrate the imbalance of oversampled teaching data with a bar graph. The bar chart shows that the number of samples of the minority class of interest has increased, but the number of samples of the majority class has remained the same. The amount of imbalances has decreased significantly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la55FsAXPTWo"
      },
      "outputs": [],
      "source": [
        "# Oversampling with the SVMSMOTE algorithm\n",
        "data2_teaching_oversampled, classes2_teaching_oversampled = SVMSMOTE(random_state=0).fit_resample(data2_teaching, classes2_teaching)\n",
        "\n",
        "# Havainnollistetaan opetusdatan epäbalanssia pylväsdiagrammilla\n",
        "plt.figure(figsize=(7,6))\n",
        "categories_teaching_oversampled, quantities_teaching_oversampled = np.unique(classes2_teaching_oversampled.astype('U'), return_counts=True)\n",
        "plt.bar(categories_teaching_oversampled, quantities_teaching_oversampled, color=['red','green'])\n",
        "plt.xlabel('Luokka')\n",
        "plt.ylabel('Opetusnäytteiden lukumäärä')\n",
        "plt.title('Ylinäytteistetyn öljyvuotodatan opetusnäytteiden lukumäärä luokkaa kohden')\n",
        "plt.show()\n",
        "\n",
        "# Print the number of samples of teaching data per class\n",
        "print('Opetusdatan luokassa {} on {} näytettä ja luokassa {} on {} näytettä'.format(categories_teaching_oversampled[0], quantities_teaching_oversampled[0], categories_teaching_oversampled[1], quantities_teaching_oversampled[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD4IcSN3PTWo"
      },
      "source": [
        "Taught with oversampled oil spill data's teaching samples using random forest, logistic regression, and k-nearest neighbor classifiers. Plot ROC curves for all three classifiers on the graph and calculate the corresponding ROC AUC values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqh_IVEoPTWo"
      },
      "outputs": [],
      "source": [
        "# Teach random forest, logistic regression and k-nearest neighbour classifiers with oversampled oil spillage data\n",
        "classifier2_random_forest_oversampled = RandomForestClassifier(n_estimators=100, random_state=0).fit(data2_teaching_oversampled, classes2_teaching_oversampled)\n",
        "classifier2_logistic_regression_oversampled = LogisticRegression(C=50, solver='liblinear', random_state=0).fit(data2_teaching_oversampled, classes2_teaching_oversampled)\n",
        "classifier2_knn_oversampled = KNeighborsClassifier(n_neighbors=35).fit(data2_teaching_oversampled, classes2_teaching_oversampled)\n",
        "\n",
        "# Calculate posterior probabilities for test data\n",
        "posterior_probablity_random_forest_oversampled = classifier2_random_forest_oversampled.predict_proba(data2_test)[:, 1]\n",
        "posterior_probablity_logistic_regression_oversampled = classifier2_logistic_regression_oversampled.predict_proba(data2_test)[:, 1]\n",
        "posterior_probablity_knn_oversampled = classifier2_knn_oversampled.predict_proba(data2_test)[:, 1]\n",
        "\n",
        "# Calculate Roc-curves\n",
        "fpr_random_forest_oversampled, tpr_random_forest_oversampled, _ = roc_curve(classes2_test, posterior_probablity_random_forest_oversampled)\n",
        "fpr_logistic_regression_oversampled, tpr_logistic_regression_oversampled, _ = roc_curve(classes2_test, posterior_probablity_logistic_regression_oversampled)\n",
        "fpr_knn_oversampled, tpr_knn_oversampled, _ = roc_curve(classes2_test, posterior_probablity_knn_oversampled)\n",
        "\n",
        "# Draw the ROC curves of all three classifiers on the graph\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(fpr_random_forest_oversampled, tpr_random_forest_oversampled, label='Satunnaismetsä')\n",
        "plt.plot(fpr_logistic_regression_oversampled, tpr_logistic_regression_oversampled, label='Logistinen regressio')\n",
        "plt.plot(fpr_knn_oversampled, tpr_knn_oversampled, label='k-nearest neigbour classifier')\n",
        "plt.xlabel('1-Specificity')\n",
        "plt.ylabel('Recall')\n",
        "plt.title('ROC curves with classifier taught with oversampled teaching data')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Print ROC AUC values corresponding to ROC-curves\n",
        "print('Random forest ROC AUC value: {}'.format(round(roc_auc_score(classes2_test, posterior_probablity_random_forest_oversampled),3)))\n",
        "print('Logistic regression ROC AUC value: {}'.format(round(roc_auc_score(classes2_test, posterior_probablity_logistic_regression_oversampled),3)))\n",
        "print('k-nearest neigbour classifier ROC AUC value: {}'.format(round(roc_auc_score(classes2_test, posterior_probablity_knn_oversampled),3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpOvTkyaPTWp"
      },
      "source": [
        "Plot a positive predictive value for the classifiers - recall the curves and calculate the corresponding PR AUC values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WswF80ELPTWq"
      },
      "outputs": [],
      "source": [
        "# Calculate PR curves\n",
        "precision_values_random_forest_oversampled, recalls_random_forest_oversampled, _ = precision_recall_curve(classes2_test, posterior_probablity_random_forest_oversampled)\n",
        "precision_values_logistic_regression_oversampled, recalls_logistic_regression_oversampled, _ = precision_recall_curve(classes2_test, posterior_probablity_logistic_regression_oversampled)\n",
        "precision_values_knn_oversampled, recalls_knn_oversampled, _ = precision_recall_curve(classes2_test, posterior_probablity_knn_oversampled)\n",
        "\n",
        "# Draw the PR curves of all three classifiers on the graph\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(recalls_random_forest_oversampled, precision_values_random_forest_oversampled, label='Random forest')\n",
        "plt.plot(recalls_logistic_regression_oversampled, precision_values_logistic_regression_oversampled, label='Logistic regression')\n",
        "plt.plot(recalls_knn_oversampled, precision_values_knn_oversampled, label='k-nearest neigbour classifier')\n",
        "plt.xlabel('recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision - recall curves with classifier taught with oversampled teaching data')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Print ROC AUC values corresponding to ROC-curves\n",
        "print('Random forest PR AUC value: {}'.format(round(auc(recalls_random_forest_oversampled, precision_values_random_forest_oversampled),3)))\n",
        "print('Logistic regression PR AUC value: {}'.format(round(auc(recalls_logistic_regression_oversampled, precision_values_logistic_regression_oversampled),3)))\n",
        "print('k-nearest neigbour classifiern PR AUC value: {}'.format(round(auc(recalls_knn_oversampled, precision_values_knn_oversampled),3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITzn8Q9IPTWq"
      },
      "source": [
        "Lasketaan lopuksi kaikki luokittelijoiden suorituskykyä kuvaavat mitta-values ja esitetään ne taulukossa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLbBDkylPTWq"
      },
      "outputs": [],
      "source": [
        "# Make table for presenting performance measurement values\n",
        "measurement_values_oversampled = []\n",
        "measurement_values_oversampled.append(['','$\\\\bf{accuracy}$','$\\\\bf{recall}$','$\\\\bf{Positive}$\\n $\\\\bf{predictive value}$','$\\\\bf{F1 score}$','$\\\\bf{ROC\\\\ AUC}$','$\\\\bf{PR\\\\ AUC}$'])\n",
        "measurement_values_oversampled.append(calculate_measurement_values(data2_test, classes2_test, classifier2_random_forest_oversampled, '$\\\\bf{Random forest}$'))\n",
        "measurement_values_oversampled.append(calculate_measurement_values(data2_test, classes2_test, classifier2_logistic_regression_oversampled, '$\\\\bf{Logistic\\\\ regression}$'))\n",
        "measurement_values_oversampled.append(calculate_measurement_values(data2_test, classes2_test, classifier2_knn_oversampled, '$\\\\bf{k-nearest}$\\n $\\\\bf{neighbour\\\\ classifier}$'))\n",
        "\n",
        "# For comparison, both tables are printed one below the other\n",
        "table_oversampled = plt.gca().table(cellText=measurement_values_oversampled, loc='center', cellLoc='center')\n",
        "table_oversampled.auto_set_font_size(False)\n",
        "table_oversampled.set_fontsize(9)\n",
        "table_oversampled.scale(1,3)\n",
        "plt.gca().axis('off')\n",
        "plt.title('Performance measures for classifiers taught with oversampled oil spill data teaching samples')\n",
        "\n",
        "plt.figure()\n",
        "table = plt.gca().table(cellText=measurement_values, loc='center', cellLoc='center')\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(9)\n",
        "table.scale(1,3)\n",
        "plt.gca().axis('off')\n",
        "plt.title('Performance metrics for classifiers taught with teaching samples of unbalanced oil spill data ')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkvqEXhNPTWq"
      },
      "source": [
        "**Compare the measured values, ROC curves, and precision-recall curves of the k-closest neighbor classifier taught with the original teaching data and the k-nearest neighbor taught with the oversampled teaching data. Did the classifier's performance improve when samples from a particular minority class were to be correctly identified?**\n",
        "\n",
        "`Your answer here`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjLOoUlzPTWq"
      },
      "source": [
        "# Feedback\n",
        "\n",
        "Finaly answer following questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuI6xF5tPTWr"
      },
      "source": [
        "**How much time did you spend doing this exercise?**\n",
        "\n",
        "`Your answer here`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9y0Y7DJPTWr"
      },
      "source": [
        "**Did you encounter any problems or challenges while doing the exercise? Were the notebook sufficiently comprehensive instructions for doing the exercise?**\n",
        "\n",
        "`Your answer here`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvKYzuqKPTWr"
      },
      "source": [
        "**Other feedback related to to this exercise**\n",
        "\n",
        "`Your answer here`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "I3dPfZurPTWr"
      },
      "source": [
        "# Returning the exercise\n",
        "\n",
        "1. Before you return this notebook **make sure that code in notebook works properly** and returns all necessary values by choosing from menu `Kernel -> Restart & Run All`! also make sure you have answer all questions on **bold**\n",
        "2. **Contrary to previous exercises** do not clear the printouts and variables, but press the save button after completing Step 1!\n",
        "3. Rename this notebook in following format **`JT_H3_[student_number(s)].ipynb`** (e.g `JT_H3_1234567.ipynb` or if you have group `JT_H3_1234567_2345678_3456789.ipynb`)\n",
        "4. Return **only** solved notebook(`file ending with .ipynb`) to moodle programming exercise 3. Everyone must return file to moodle even if you work in a group. **Don't include working directory or other files** when you return the exercise.\n",
        "5. Finally go answer questions in moodle related to programming exercise 3. Everyone in your group must answer to questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ghf8FDD5PTWr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}