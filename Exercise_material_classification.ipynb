{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simulate111/Johdatus-teko-lyyn-Introduction-to-Artificial-Intelligence/blob/main/Exercise_material_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onedrivedownloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAQCoH-6PKqm",
        "outputId": "fc335f21-ad98-49f5-e107-93b338eaf17c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onedrivedownloader\n",
            "  Downloading onedrivedownloader-1.1.3-py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from onedrivedownloader) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from onedrivedownloader) (4.66.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->onedrivedownloader) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->onedrivedownloader) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->onedrivedownloader) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->onedrivedownloader) (2024.2.2)\n",
            "Installing collected packages: onedrivedownloader\n",
            "Successfully installed onedrivedownloader-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtmshaTIO-EM",
        "outputId": "6193fbaf-ef65-4474-9a68-f48371d625d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.91M/2.91M [00:02<00:00, 1.27MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting files: 100%|██████████| 15/15 [00:00<00:00, 457.32it/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from onedrivedownloader import download\n",
        "\n",
        "link2data = 'https://unioulu-my.sharepoint.com/:u:/g/personal/jukmaatt_univ_yo_oulu_fi/ET3iUnWprHVGqjKavqhFmz4BpCN4WGYrSovJNbIBzkD3JQ?e=SK1SlV'\n",
        "\n",
        "if not os.path.exists('./data'):\n",
        "    print('Downloading data')\n",
        "    download(link2data, filename='./files.zip', unzip=True, unzip_path='./')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF_zb0avO-EN"
      },
      "source": [
        "# <center>521160P Introduction to artificial intelligence<br><br>Exercise material<br><br>Classification<br></center>\n",
        "\n",
        "In the supervised learning classification, the classifier is taught with data containing class information. The classifier is then able to make predictions for unknown test samples, i.e., the categories to which they are most likely to belong. Finally the success of the predictions can be assessed when the correct categories of test samples are known.\n",
        "\n",
        "### Data division\n",
        "\n",
        "Data is divided into teaching data, validation data, and test data. Samples of teaching data are used as their name implies to teach the classifier. Samples of validation data in turn are used to adjust the hyperparameters of the classifier being taught. Samples of test data are used to test the performance of the classifier. The test samples are well suited for this purpose as they are already completely unknown to the classifier. Based on the classification result of the test data, the best of the classified classifiers for the classification problem to be addressed is selected. In Figure 1, the data is divided into teaching, validation, and test data followed by a set of classifiers taught and validated. By predicting the classes for the test data samples with the classifiers the classification accuracies can be calculated from the classification results and the best classifier can be selected.\n",
        "\n",
        "<br>\n",
        "<div style=\"width:image width px; font-size:80%; text-align:center;\">\n",
        "    <center>\n",
        "    <img src='https://github.com/simulate111/Johdatus-teko-lyyn-Introduction-to-Artificial-Intelligence/blob/main/imgs/luokittelu1.png?raw=1' width='550' height='auto' style='padding-bottom:0.5em;' />\n",
        "    </center>\n",
        "    <span>Figure 1. Teaching data, validation data and test data usage.</span>\n",
        "</div>\n",
        "<br>\n",
        "\n",
        "If the size of the teaching data is too small, over-learning occurs easily. In this case the classifier has learned too precisely the most characteristic features of a small sample of teaching samples. On the other hand if too little test data is used the classification accuracies of the classifiers are unreliable. If the size of the validation data is too small optimal values of the hyperparameters will not be found for the classifiers so the classification results will not be the best possible. When there is sufficient initial data  the overall division ratio for the data is 80:10:10, where as much of the sample  as possible is used to teach the classifier (80%) and a smaller proportion (10% + 10%) to validate and test the classifier.\n",
        "\n",
        "When the amount of validation data cannot be increased due to the scarcity of the original data, cross-validation must be used. The teaching data is divided into subsets of S piecesone of which is used one at a time to validate the classifier and the rest of the S-1 subset to teach the classifier. This is repeated S times so that each subset has once been validation data. Finally, how good the classifier is is assessed by averaging the classification accuracies of the validation data.\n",
        "\n",
        "For example, the task may be to identify whether a bird or something else is in the picture. In this case, the data must contain two types of samples: images with a bird and the so-called negative samples, i.e., images that do not contain birds but cars, airplanes, dogs, etc. Before the classifiers are taught, the images are categorized by assigning the bird images to Class 1 and the non-bird images to Class 2. The categorized data is then divided into teaching, validation, and test data. Classifiers taught with teaching data and validated for validation data identify test data for samples when there is a bird in the image and when there is something else in it. Finally, from the classification result of the test data, the classification accuracies are calculated and the best classifier is selected to perform that task.\n",
        "\n",
        "### Evaluating the performance of a classifier\n",
        "\n",
        "In the classification, the performance of the classifier is evaluated by the measured values calculated from the confusion matrix of the test data. The confusion matrix tells you how many of the samples are classified correctly and how many incorrectly and to which categories the incorrectly classified samples actually belong. In this exercise material in the confusion matrix the correct classes are placed in rows and the classes predicted by the classifier in columns, but the placement can be done the other way around. If a category in a particular row of the confusion matrix has numbers in different columns than its own row number, the classifier has classified the samples into the wrong categories. Figure 2 shows an example of a confusion matrix with 9 classes. The best result for the classifier is obtained when the main diagonal of its confusion matrix has all the categories of test data predicted by the classifier.\n",
        "\n",
        "<br>\n",
        "<div style=\"width:image width px; font-size:80%; text-align:center;\">\n",
        "    <center>\n",
        "    <img src='https://github.com/simulate111/Johdatus-teko-lyyn-Introduction-to-Artificial-Intelligence/blob/main/imgs/luokittelu2.png?raw=1' width='500' height='auto' style='padding-bottom:0.5em;' />\n",
        "    </center>\n",
        "    <span>Figure 2. An example of a confusion matrix for a nine-class classification problem. Predicted classes (x-axis) and correct classes (y-axis) </span>\n",
        "</div>\n",
        "<br>\n",
        "\n",
        "However, dimensional classification accuracy alone does not provide a good enough picture of classifier performance, especially in the case of unbalanced data. Unbalanced data have clearly different numbers of samples in different categories. When unbalanced data is being processed in a real situation, the first step is to try to balance it by oversampling or undersampling. However, this is not always possible. The classification sensitivity/recall/true positive rate, specificity, true negative rate, positive predictive value / precision, and negative negative predictive value to describe the performance of the classifier. The following is an example of how different performance metrics differ.\n",
        "\n",
        "Of the 100 people in the village, 20 get a rare disease whose symptoms do not start to appear until a week after becoming infected. It is the job of the village doctor to identify the people infected with the device designed to detect the disease so that treatment can be started as early as possible. The device estimates that 30 out of 100 people have contracted the disease. After a week, however, it turns out that out of the 30 sick people predicted, 15 were actually carriers (TP) and 15 were healthy (FP). Because there were a total of 20 patients, 5 people were identified as healthy, even though they were actually ill (FN). Of the people in the village, 65 were identified as fairly healthy (TN). Measurement values describing the performance of the device can now be calculated using Equations (1), (2), (3), (4) and (5). Figure 3 illustrates an example of text in a series of images. In Figure 4, a confusion matrix is formed for the text example.\n",
        "\n",
        "<br>\n",
        "<div style=\"width:image width px; font-size:80%; text-align:center;\">\n",
        "    <center>\n",
        "    <img src='https://github.com/simulate111/Johdatus-teko-lyyn-Introduction-to-Artificial-Intelligence/blob/main/imgs/luokittelu3.png?raw=1' width='550' height='auto' style='padding-bottom:0.5em;' />\n",
        "    </center>\n",
        "    <span>Figure 3. An example of text illustrated with a series of images.</span>\n",
        "</div>\n",
        "<br>\n",
        "\n",
        "<br>\n",
        "<div style=\"width:image width px; font-size:80%; text-align:center;\">\n",
        "    <center>\n",
        "    <img src='https://github.com/simulate111/Johdatus-teko-lyyn-Introduction-to-Artificial-Intelligence/blob/main/imgs/luokittelu4.png?raw=1' width='300' height='auto' style='padding-bottom:0.5em;' />\n",
        "    </center>\n",
        "    <span>Figure 4. Confusion matrix for text example. </span>\n",
        "</div>\n",
        "<br>\n",
        "\n",
        "* **TP**, true positives, hit\n",
        "* **FP**, false positives, false alarm\n",
        "* **FN**, false negatives, miss\n",
        "* **TN**, true negatives, correct rejection\n",
        "\n",
        "Sensitivity/recal/true positive rate:\n",
        "<br><br>\n",
        "\\begin{equation}\n",
        "\\frac{TP}{P} = \\frac{TP}{TP+FN} = \\frac{15}{15+5} = 75 \\% \\tag{1}\n",
        "\\end{equation}\n",
        "\n",
        "Specificity:\n",
        "<br><br>\n",
        "\\begin{equation}\n",
        "\\frac{TN}{N} = \\frac{TN}{TN+FP} = \\frac{65}{65+15} = 81,25 \\% \\tag{2}\n",
        "\\end{equation}\n",
        "\n",
        "Positive predictive value / accuracy:\n",
        "<br><br>\n",
        "\\begin{equation}\n",
        "\\frac{TP}{TP+FP} = \\frac{15}{15+15} = 50 \\% \\tag{3}\n",
        "\\end{equation}\n",
        "\n",
        "Negative predictive value :\n",
        "<br><br>\n",
        "\\begin{equation}\n",
        "\\frac{TN}{TN+FN} = \\frac{65}{65+5} = 92,9 \\% \\tag{4}\n",
        "\\end{equation}\n",
        "\n",
        "Classification accuracy:\n",
        "<br><br>\n",
        "\\begin{equation}\n",
        "\\frac{TP+TN}{P+N} = \\frac{TP+TN}{TP+FN+TN+FP} = \\frac{15+65}{15+5+65+15} = 80 \\% \\tag{5}\n",
        "\\end{equation}\n",
        "<br><br>\n",
        "\n",
        "The binary two-class classification problem can be viewed as probability density distributions. In this case, the class boundary separating the samples of the categories is defined as a numerical threshold. By adjusting the threshold value, for example, the number of false rejects (FN) can be reduced while increasing the number of false alarms (FP). Calculated from different thresholds, a ROC (receiver operating charasterictic curve) curve can be generated, with a sensitivity on the vertical axis and 1-specificity (FPR) on the horizontal axis [1]. Figure 5 shows the probability density distributions of the two classes and the corresponding ROC curve. For example, when identifying a serious illness, the sensitivity value, which indicates how many of all infected individuals (TP + FN) were identified as ill (TP), should be as large as possible. This is accomplished by selecting a point on the ROC curve in Figure 5 where the sensitivity is given the highest possible value, which is reflected in an increase in the value of 1-specificity (FPR) (i.e., a decrease in the value of specificity). Increasing the sensitivity value with the ROC curve corresponds to shifting the threshold value to the left in the graph of probability density distributions.\n",
        "\n",
        "<br><br>\n",
        "<div style=\"width:image width px; font-size:80%; text-align:center;\">\n",
        "    <center>\n",
        "    <img src='https://github.com/simulate111/Johdatus-teko-lyyn-Introduction-to-Artificial-Intelligence/blob/main/imgs/luokittelu5.png?raw=1' width='800' height='auto' style='padding-bottom:0.5em;' />\n",
        "    </center>\n",
        "    <span>Figure 5. Probability density distributions at the threshold and the corresponding point on the ROC curve.</span>\n",
        "</div>\n",
        "<br><br>\n",
        "\n",
        "The best result for the classifier is obtained when the ROC curve passes through the point (0,1) in the upper left corner. If the ROC curve passes linearly through the lower left corner point (0,0) and the upper right corner point (1,1), the classifier is as good as the grade would be randomly evaluated for each test sample. The result of the ROC curve can be converted to a numerical value by calculating the ROC AUC value (area under the receiver operating charasteristic), which indicates how large the area is below the ROC curve when the values of both axes vary between 0 and 1. ROC AUC value of the complete classifier is 100% and the ROC AUC of the random classifier is 50%. Figure 6 shows the ROC curve for the complete classifier in green, the ROC curve for the random classifier in blue, and the corresponding ROC AUC values.\n",
        "\n",
        "<br><br>\n",
        "<div style=\"width:image width px; font-size:80%; text-align:center;\">\n",
        "    <center>\n",
        "    <img src='https://github.com/simulate111/Johdatus-teko-lyyn-Introduction-to-Artificial-Intelligence/blob/main/imgs/luokittelu6.png?raw=1' width='350' height='auto' style='padding-bottom:0.5em;' />\n",
        "    </center>\n",
        "    <span>Figure 6. ROC curves and ROC AUC values for the complete classifier and random classifier. </span>\n",
        "</div>\n",
        "<br><br>\n",
        "\n",
        "Another way to evaluate the performance of a classifier at different thresholds is a positive prediction value - the precision-recall curve. In it, the horizontal axis has sensitivity and the vertical axis has a positive prediction value. Positive prediction value - the sensitivity curve should be used especially when processing unbalanced data. When testing with unbalanced data, the ROC curve gives an overly optimistic picture of the performance of the classifier. Positive prediction value - sensitivity to the curve data imbalance does not have a particularly large distorting effect. The positive predictor value of the perfect classifier - the sensitivity curve passes through the point in the upper right corner (1,1). The result of the positive prediction value - sensitivity curve can also be converted to a numerical PR AUC (area under the Precision recall curve) by calculating the area under the curve. Figure 7 shows the positive predictor of the complete classifier - sensitivity curve with a PR AUC of 100%.\n",
        "\n",
        "<br><br>\n",
        "<div style=\"width:image width px; font-size:80%; text-align:center;\">\n",
        "    <center>\n",
        "    <img src='https://github.com/simulate111/Johdatus-teko-lyyn-Introduction-to-Artificial-Intelligence/blob/main/imgs/luokittelu7.png?raw=1' width='350' height='auto' style='padding-bottom:0.5em;' />\n",
        "    </center>\n",
        "    <span>Figure 7. Positive predictor of the complete classifier - sensitivity curve and PR AUC value.</span>\n",
        "</div>\n",
        "<br><br>\n",
        "\n",
        "\n",
        "\n",
        "## Lähteet\n",
        "\n",
        "[1] Duda R., Hart P. & Stork D. (2012) Pattern classification. John Wiley & Sons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cSVwBVi8O-EO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}