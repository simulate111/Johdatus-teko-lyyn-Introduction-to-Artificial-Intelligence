{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "plt.rcParams['figure.figsize'] = (15, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onedrivedownloader import download\n",
    "\n",
    "link2data = 'https://unioulu-my.sharepoint.com/:u:/g/personal/jukmaatt_univ_yo_oulu_fi/EccjaL-zb_JKiZA_OBR3-VsBOa69ZTuk-yDw7j7hsKqaFw?e=ZqIJk0'\n",
    "\n",
    "if not os.path.exists('./data'):\n",
    "    print('Downloading data')\n",
    "    download(link2data, filename='./files.zip', unzip=True, unzip_path='./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>521160P Introduction to artificial intelligence<br><br>Exercise #2<br><br>Regression<br></center>\n",
    "\n",
    "In this exercise we are working with fitting regression models to data and logistic regression. **Look return deadlines from moodle**. It is possible to get 4 points (2p + 2p) from this exercise.\n",
    "\n",
    "If you have any questions related to exercises or you face any problems during this exercise please use moodle forum for **programming exercise 2**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First fill in your group information (name and student number)**\n",
    "\n",
    "# Group member information :\n",
    "\n",
    "* **Member 1 :** `First_name Surname 1234567 `\n",
    "* **Member 2 :** `Maija Meikäläinen 2345678 `\n",
    "* **Member 3 :** `... `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1. Fitting regression models\n",
    "\n",
    "In this task, a linear, polynomial, and exponential regression model is created to determine the dependence of the stopping distance and speed of a car. The task uses data collected in the 1920s on stopping distances by cars at different speeds. The stopping distance consists of the braking distance and the distance corresponding to the response time. The original data contains a total of 50 samples and two variables: stopping distance in feet and speed in miles per hour.\n",
    "\n",
    "Convert the stopping distance to meters and the speed to km / h and place the data samples on the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data cars into numpy-lists, variable X refers car's velocity and variable Y refers to stopping distance\n",
    "X, Y = np.loadtxt('data/cars.txt', delimiter=',', unpack=True)\n",
    "\n",
    "# Convert variable X and Y to km/h and meters\n",
    "X = X*1.609344\n",
    "Y = Y*0.3048\n",
    "\n",
    "# place data samples to graph\n",
    "plt.scatter(X, Y, color=\"black\",s=10, marker='o')\n",
    "plt.title('Car\\'s stopping distance with different velocities')\n",
    "plt.xlabel('Velocity (km/h)')\n",
    "plt.ylabel('Stopping distance (m)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, teaching data is used to teach the model and test data is used to evaluate the performance of the model being taught. In this case, teaching means determining the appropriate function parameters based on the samples of teaching data. Initially, the data is divided into teaching data and test data by the [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function of the scikit-learn library. The function takes the x-axis score, the y-axis score, and the absolute size of the test data as parameters. 70% of the samples, i.e. 35 samples, are used to teach the model and 30% of the samples, i.e. 15 samples, to test the model.\n",
    "\n",
    "Your task is to evaluate the performance of the linear, polynomial, and exponential regression model using the square of the correlation coefficient and the root mean square error, and to predict the stopping distance of the car from a given speed with different models. \n",
    "\n",
    "## Linear regression model\n",
    "\n",
    "Let's teach linear regression model with teaching data. This can be done with the numpy library functions [np.polyfit ()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html) and [np.poly1d()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.poly1d.html). Place samples of teaching data on the graph as blue dots and samples of test data as red dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data to teaching data and testing data\n",
    "X_teaching, X_test, Y_teaching, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "# Place samples of teaching data as blue dots on the graph and samples of test data as red dots \n",
    "plt.scatter(X_teaching, Y_teaching, color=\"blue\",s=10, marker='o')\n",
    "plt.scatter(X_test, Y_test, color=\"red\",s=10, marker='o')\n",
    "plt.title('Car\\'s stopping distance relative to car\\'s velocity on linear model')\n",
    "plt.xlabel('Velocity (km/h)')\n",
    "plt.ylabel('Stopping distance (m)')\n",
    "\n",
    "# Optimize line's parameters k and b with least squares methdod using polyfit-function from numpy library\n",
    "# Function uses x-coordinates, y-coordinates and degree of polynomial function as parameters\n",
    "# Line is first degree polynomial function\n",
    "line_parameters = np.polyfit(X_teaching, Y_teaching, 1)\n",
    "\n",
    "# Create linear model using numpy-library's poly1d function after finding optimal line parameters\n",
    "linear_model = np.poly1d(line_parameters)\n",
    "\n",
    "# Draw line on the graph in range [min(X_teaching), max(X_teaching)]\n",
    "X_line = np.linspace(min(X_teaching), max(X_teaching))\n",
    "Y_line = linear_model(X_line)\n",
    "plt.plot(X_line, Y_line, c='black', linewidth=2)\n",
    "plt.show()\n",
    "\n",
    "def sign(number):\n",
    "    \"\"\"\n",
    "    In this function we get sign of equation parameter for printing\n",
    "    \"\"\"\n",
    "    if number >= 0:\n",
    "        return '+'\n",
    "    return '-'\n",
    "\n",
    "# Print the equation of the fitted line \n",
    "print('The equation of the fitted line: y = {} x {} {}'.format(round(line_parameters[0],4), sign(line_parameters[1]), abs(round(line_parameters[1],4))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the fitted linear model is then evaluated using test data. The square of the correlation coefficient and the root mean square error, which are calculated by the following equations, are used as performance measures. \n",
    "\n",
    "\\begin{equation}\n",
    "r^2 = \\frac{SSR}{SST} = 1 - \\frac{SSE}{SST} = 1 - \\frac{\\sum\\limits_{i=1}^n (Y_{i} - f(X_{i}))^2}{\\sum\\limits_{i=1}^n (Y_{i} - \\bar{Y})^2}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "MSE = \\frac{1}{n} \\sum\\limits_{i=1}^n (Y_{i} - f(X_{i}))^2\n",
    "\\end{equation}\n",
    "\n",
    "Implement performance measurement equations above using numpy library functions [np.sum()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html), [np.square()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.square.html), [np.mean()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html). For the mean square error, you also need the number of samples.\n",
    "\n",
    "After getting measurements check for the linear model that you get the values corresponding to the ready-made scikit-learn library functions [sm.r2_score()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) and [sm.mean_squared_error()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_error(Y,Y_predict):\n",
    "    \"\"\"\n",
    "    In this function calculate mean square error when you know y-coordinate values for test data \n",
    "    and predicted y-coordinate values\n",
    "    \"\"\"\n",
    "    sample_ammount = Y.size\n",
    "    #-------- YOUR CODE HERE --------\n",
    "    # Calculate mean square error (Tip: you need np.sum() and np.square() functions from numpy library)\n",
    "    \n",
    "    # Function returns mean square error    \n",
    "    #-----------------------------------\n",
    "\n",
    "def square_of_correlation_coefficient(Y, Y_predict):\n",
    "    \"\"\"\n",
    "    In this function calculate square of the correlation coefficient when you know y-coordinate values for test data \n",
    "    and predicted y-coordinate values\n",
    "    \"\"\"\n",
    "    #-------- YOUR CODE HERE --------\n",
    "    # Calculate SSE (Tip: you need np.sum() and np.square from numpy library)\n",
    "    \n",
    "    # Calculate SST (Tip: you need np.sum(), np.square() and np.mean() from numpy library)\n",
    "    \n",
    "    # Calculate square of the correlation coefficient\n",
    "    \n",
    "    # Function returns square of the correlation coefficient\n",
    "    \n",
    "    #-----------------------------------\n",
    "\n",
    "print('Square of correlation coefficient for linear model using scikit-learn library\\'s function: ', sm.r2_score(Y_test, linear_model(X_test)))\n",
    "print('Mean square error for linear model using scikit-learn library\\'s function: ', sm.mean_squared_error(Y_test, linear_model(X_test)))\n",
    "\n",
    "print('\\nSquare of correlation coefficient for linear model using function you implemented: ', square_of_correlation_coefficient(Y_test, linear_model(X_test)))\n",
    "print('Mean square error for linear model using function you implemented: ', mean_square_error(Y_test, linear_model(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial regression model\n",
    "\n",
    "The teaching of the polynomial regression model with the teaching data is performed. Place samples of teaching data on the graph as blue dots and samples of test data as red dots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place samples of teaching data as blue dots on the graph and samples of test data as red dots \n",
    "plt.scatter(X_teaching, Y_teaching, color=\"blue\",s=10, marker='o')\n",
    "plt.scatter(X_test, Y_test, color=\"red\",s=10, marker='o')\n",
    "\n",
    "plt.title('Car\\'s stopping distance relative to car\\'s velocity on polynomial model')\n",
    "plt.xlabel('Velocity (km/h)')\n",
    "plt.ylabel('Stopping distance (m)')\n",
    "\n",
    "# Optimize parabola's parameters with least squares method using polyfit function from numpy library\n",
    "parabola_parameters = np.polyfit(X_teaching, Y_teaching, 2)\n",
    "\n",
    "# Create polynomial model with poly1d function from numpy library after optimal parameters for parabola are found\n",
    "polynomial_model = np.poly1d(parabola_parameters)\n",
    "\n",
    "# Draw parabola on graph in range [min(X_teaching), max(X_teaching)]\n",
    "X_parabola = np.linspace(min(X_teaching), max(X_teaching))\n",
    "Y_parabola = polynomial_model(X_parabola)\n",
    "plt.plot(X_parabola, Y_parabola, c='black', linewidth=2)\n",
    "plt.show()\n",
    "\n",
    "# Print fitted parabola's equation\n",
    "print('Equation of fitted parabola:  y = {} x^2 {} {} x {} {}'.format(round(parabola_parameters[0],4), sign(parabola_parameters[1]), abs(round(parabola_parameters[1],4)),sign(parabola_parameters[2]), abs(round(parabola_parameters[2],4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the square of the correlation coefficient and the mean square error for the polynomial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Square of correlation coefficient for polynomial model: ', square_of_correlation_coefficient(Y_test, polynomial_model(X_test)))\n",
    "print('Mean square error for polynomial model: ', mean_square_error(Y_test, polynomial_model(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential regression model\n",
    "\n",
    "Teaching an exponential regression model with teaching data is performed. Place samples of teaching data in the graph as blue dots and samples of test data in red dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place samples of teaching data as blue dots on the graph and samples of test data as red dots \n",
    "plt.scatter(X_teaching, Y_teaching, color=\"blue\",s=10, marker='o')\n",
    "plt.scatter(X_test, Y_test, color=\"red\",s=10, marker='o')\n",
    "\n",
    "plt.title('Car\\'s stopping distance relative to car\\'s velocity on exponential model')\n",
    "plt.xlabel('Velocity (km/h)')\n",
    "plt.ylabel('Stopping distance (m)')\n",
    "\n",
    "def exponential_model(x):\n",
    "    \"\"\"\n",
    "    Tässä funktiossa toteutetaan eksponentiaalinen regressiomalli\n",
    "    \"\"\"\n",
    "    global exponential_function_parameters\n",
    "    # Optimize exponential function parameters with least squares methdod using polyfit-function from numpy library\n",
    "    # ln(y) = kx + b <=> y = exp(kx+b)\n",
    "    \n",
    "    exponential_function_parameters = np.polyfit(X_teaching, np.log(Y_teaching), 1)\n",
    "    return np.exp(exponential_function_parameters[0]*x + exponential_function_parameters[1])\n",
    "\n",
    "# Draw exponential model on graph in range [min(X_teaching), max(X_teaching)]\n",
    "X_exponential = np.linspace(min(X_teaching), max(X_teaching))\n",
    "Y_exponential = exponential_model(X_exponential)\n",
    "plt.plot(X_exponential, Y_exponential, c='black', linewidth=2)\n",
    "plt.show()\n",
    "\n",
    "# Print equation of fitted exponential function\n",
    "print('Equation of fitted exponential function:  y = exp^({} x {} {})'.format(round(exponential_function_parameters[0],4), sign(exponential_function_parameters[1]), abs(round(exponential_function_parameters[1],4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the square of the correlation coefficient and the mean square error for the exponential model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Square of correlation coefficient for exponential model: ', square_of_correlation_coefficient(Y_test, exponential_model(X_test)))\n",
    "print('Mean square error for exponential model: ', mean_square_error(Y_test, exponential_model(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which model worked best for the test data based on performance measurements?**\n",
    "\n",
    "`Your answer here`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally using different models predict how long the stopping distance will be when it is known that the motorist is braking from speed of 80 km/h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Stopping distance from velocity of 80 km/h predicted using linear model: \", round(linear_model(80), 2), \"meters\")\n",
    "print(\"Stopping distance from velocity of 80 km/h predicted using polynomial model: \", round(polynomial_model(80), 2), \"meters\")\n",
    "print(\"Stopping distance from velocity of 80 km/h predicted using exponential model: \", round(exponential_model(80), 2), \"meters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**According to the traffic safety website, the stopping distance of a modern car on a dry road at a speed of 80 km/h is exactly 50 meters. Based on this knowledge, which one or more of the models taught give realistic predictions for this test sample?**\n",
    "\n",
    "`Your answer here`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2. Logistic regression\n",
    "\n",
    "On second task logistic regression classifiers to predict the risk of developing diabetes in women of the Pima Native American tribe is created. The data used in the task have been collected from women over the age of 21 in the Pima Native American tribe by measuring various variables that correlate with diabetes. The variables used are number of pregnancies, fasting plasma glucose, blood pressure, skin thickness, blood insulin, body mass index, coefficient calculated from the incidence of diabetes in the family, and age. The data include 500 patients with diabetes and 268 healthy patients.\n",
    "\n",
    "Download data and evaluate distribution of variables between diabetic and healthy patients using box-segment patterns and histograms.In the box-segment pattern, the yellow line indicates the location of the median, the top and bottom of the box the median of the upper and lower quarters, and the maximum and minimum value of the segment data that do not contain outliers. Deviating observations are marked in the box-segment pattern with circles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data pima-indians. Variable data refers to data's values and variable classes refers to data's class information\n",
    "data = np.genfromtxt('data/pima-indians.txt', delimiter=',', usecols = (0,1,2,3,4,5,6,7))\n",
    "classes = np.genfromtxt('data/pima-indians.txt', delimiter=',', usecols = (8))\n",
    "\n",
    "data_diabetes = data[np.where(classes == 1)]\n",
    "data_no_diabetes = data[np.where(classes == 0)]\n",
    "\n",
    "# From the box-segment patterns analyze which variables correlate best with the class information \n",
    "headers = ['Ammount of pregnancies','Ammount of fasting plasma glucose in blood','Blood pressure','Skin thickness','Ammount of insulin in blood','Weight index','Prevalence of diabetes in the family ','Age']\n",
    "fig, ax = plt.subplots(2, 4)\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        ax[i, j].boxplot([data_diabetes[:,j*2+i], data_no_diabetes[:,j*2+i]], positions=[0,1])\n",
    "        ax[i, j].set_title(headers[j*2+i])\n",
    "        ax[i, j].axes.set_xticklabels(['diabetes','no diabetes'])\n",
    "plt.suptitle('Box-segment patterns of both classes for data variables ')\n",
    "\n",
    "fig, ax = plt.subplots(2, 4) \n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        ax[i, j].hist([data_diabetes[:,j*2+i],data_no_diabetes[:,j*2+i]], histtype='stepfilled', alpha=0.8, bins=40, label=['diabetes', 'no diabetes'])\n",
    "        ax[i, j].legend(loc='upper right')\n",
    "        ax[i, j].set_title(headers[j*2+i])\n",
    "plt.suptitle('Histograms of both classes for data variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the box-segment patterns and histograms, the two variables that best correlate with suffering from diabetes are selected. The most obvious differences in the distributions of the categories \"diabetes\" and \"non-diabetes\" differ in the variable fasting plasma glucose. This is seen as for example in the box-segment pattern of a variable as clearly separate boxes for data classes. When choosing the second variable the differences between the categories are not as clear but we end up with the variable weight index.\n",
    "\n",
    "Next, the data is divided into teaching data and test data in a 60:40 division ratio. The logistic regression classifiers for the selected variables individually and for their combination are then taught. Finally, the classification results of the three taught classifiers are compared.\n",
    "\n",
    "An example of a logistic regression classifier for fasting plasma glucose is taught. Draw the created model and place the test data samples on the same graph. Finally, the classification accuracy is calculated for the test data. Classification accuracy simply tells you what percentage of the test data samples the classifier classified into the correct categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data to teaching data and test data\n",
    "data_teaching, data_test, classes_teaching, classes_test = train_test_split(data, classes, test_size=0.4, random_state=0)\n",
    "\n",
    "# Convert teaching data for fasting plasma glucose in right format\n",
    "fasting_plasma_glucose_teaching = np.reshape(data_teaching[:,1], (-1,1))\n",
    "\n",
    "# Convert test data for fasting plasma glucose in right format\n",
    "fasting_plasma_glucose_test = np.reshape(data_test[:,1], (-1,1))\n",
    "\n",
    "# Initialize the classifier \n",
    "classifier_fasting_plasma_glucose = LogisticRegression()\n",
    "\n",
    "# Teach logistic regression classifier for fasting plasma glucose\n",
    "classifier_fasting_plasma_glucose.fit(fasting_plasma_glucose_teaching, classes_teaching)\n",
    "\n",
    "# Predict classes for test data samples\n",
    "classes_fasting_plasma_glucose_predicted = classifier_fasting_plasma_glucose.predict(fasting_plasma_glucose_test)\n",
    "\n",
    "# Calculate classification accuracy for fasting plasma glucose's logistic regression classifier\n",
    "classification_accuracy_fasting_plasma_glucose = accuracy_score(classes_test, classes_fasting_plasma_glucose_predicted)\n",
    "\n",
    "def logistic_sigmoid_function(X, a, b):\n",
    "    \"\"\"\n",
    "    In this function logistic regression's classifier is calculated according to sigmoid function\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-(a*X+b)))\n",
    "\n",
    "# Draw fitted function and place test data samples to same graph\n",
    "plt.plot(fasting_plasma_glucose_test, classes_test, 'o', c='r', alpha=0.5)\n",
    "X_fasting_plasma_glucose = np.linspace(min(fasting_plasma_glucose_teaching), max(fasting_plasma_glucose_teaching)+50)\n",
    "Y_fasting_plasma_glucose  = logistic_sigmoid_function(X_fasting_plasma_glucose, classifier_fasting_plasma_glucose.coef_, classifier_fasting_plasma_glucose.intercept_).ravel()\n",
    "plt.plot(X_fasting_plasma_glucose, Y_fasting_plasma_glucose, color='k', linewidth=3)\n",
    "plt.xlabel('Ammount fasting plasma glucose in blood')\n",
    "plt.ylabel('Likelihood of illness P(Y=\"diabetes\")')\n",
    "plt.show()\n",
    "\n",
    "print('The classification accuracy for the fasting plasma glucose logistic regression classifier is {}%'.format(round(100*classification_accuracy_fasting_plasma_glucose,2)))\n",
    "\n",
    "def sign(number):\n",
    "    \"\"\"\n",
    "    In this function we get sign of equation parameter for printing\n",
    "    \"\"\"\n",
    "    if number >= 0:\n",
    "        return '+'\n",
    "    return '-'\n",
    "\n",
    "# Print the logistic equation of the logistic regression classifier for fasting plasma glucose \n",
    "print('\\nLogistic function:  P(Y=\"diabetes\")= 1/(1+exp^(-({} x {} {})))'.format(round(classifier_fasting_plasma_glucose.coef_[0][0],4), sign(classifier_fasting_plasma_glucose.intercept_[0]), abs(round(classifier_fasting_plasma_glucose.intercept_[0],4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way teach a logistic regression classifier for a weight index, predict classes for test data samples, and calculate classification accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert teaching data for weight index in right format\n",
    "weight_index_teaching = np.reshape(data_teaching[:,5], (-1,1))\n",
    "\n",
    "# Convert test data for weight index in right format\n",
    "weight_index_test = np.reshape(data_test[:,5], (-1,1))\n",
    "\n",
    "# Initialize classifier\n",
    "classifier_weight_index = LogisticRegression()\n",
    "\n",
    "#-------- Your code here --------\n",
    "# Teach logistic regression classifier for weight index (Hint: .fit(teaching_data, classes_teaching_data))\n",
    "\n",
    "# Predict classes for test data samples (Hint: .predict(testdata))\n",
    "classes_weight_index_predicted = \n",
    "# Calculate classification accuracy for weight index's logistic regression classifier (Hint: accuracy_score(classes_test_data, classes_predicted))\n",
    "classification_accuracy_weight_index = \n",
    "#-----------------------------------\n",
    "\n",
    "# Draw fitted function and place test data samples to same graph\n",
    "plt.plot(weight_index_test, classes_test, 'o', c='r', alpha=0.5)\n",
    "X_weight_index = np.linspace(min(weight_index_teaching), max(weight_index_teaching)+10)\n",
    "Y_weight_index = logistic_sigmoid_function(X_weight_index, classifier_weight_index.coef_, classifier_weight_index.intercept_).ravel()\n",
    "plt.plot(X_weight_index, Y_weight_index, color='k', linewidth=3)\n",
    "plt.xlabel('Weight index')\n",
    "plt.ylabel('Likelihood of illness P(Y=\"diabetes\")')\n",
    "plt.show()\n",
    "\n",
    "print('The classification accuracy for the weight index logistic regression classifier is {}%'.format(round(100*classification_accuracy_weight_index,2)))\n",
    "\n",
    "# Print the logistic equation of the logistic regression classifier for weight index\n",
    "print('\\nLogistic function:  P(Y=\"diabetes\")= 1/(1+exp^(-({} x {} {})))'.format(round(classifier_weight_index.coef_[0][0],4), sign(classifier_weight_index.intercept_[0]), abs(round(classifier_weight_index.intercept_[0],4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, teach the logistic regression classifier of the two variables (fasting plasma glucose and body mass index), predict the categories of test data for the samples, and calculate the classification accuracy. Combine both variables in teaching data and test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both variables in teaching data\n",
    "combined_teaching = np.concatenate((fasting_plasma_glucose_teaching, weight_index_teaching), axis=1)\n",
    "\n",
    "# combine both variables in test data Yhdistetään testidataan molemmat muuttujat\n",
    "combined_test = np.concatenate((fasting_plasma_glucose_test, weight_index_test), axis=1)\n",
    "\n",
    "# Initialize classifier\n",
    "classifier_combined = LogisticRegression()\n",
    "\n",
    "#-------- Your code here --------\n",
    "# Teach logistic regression classifier for combined data (Hint: .fit(teaching_data, classes_teaching_data))\n",
    "\n",
    "# Predict classes for test data samples (Hint: .predict(testdata))\n",
    "classes_combined_predicted = \n",
    "\n",
    "# Calculate classification accuracy for combined data's logistic regression classifier (Hint: accuracy_score(classes_test_data, classes_predicted))\n",
    "classification_accuracy_combined = \n",
    "#-----------------------------------\n",
    "\n",
    "print('The classification accuracy for the two-variable logistic regression classifier is {}%'.format(round(100*classification_accuracy_combined,2)))\n",
    "# Print the logistic equation of the logistic regression classifier for combined data\n",
    "print('\\nLogistic function:  P(Y=\"diabetes\")= 1/(1+exp^(-({} x1 {} {} x2 {} {})))'.format(round(classifier_combined.coef_[0][0],4), sign(classifier_combined.coef_[0][1]), abs(round(classifier_combined.coef_[0][1],4)), sign(classifier_combined.intercept_[0]), abs(round(classifier_combined.intercept_[0],4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which of the taught classifiers worked best in terms of classification accuracy?** \n",
    "\n",
    "`Your answer here`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize two-dimensional test data and the class boundary of a two-variable classifier into a two-dimensional coordinate system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place samples of test data on a graph for diabetic and healthy patients \n",
    "plt.scatter(combined_test[np.where(classes_test==1), 0], combined_test[np.where(classes_test==1), 1], s=10, label='diabetes')\n",
    "plt.scatter(combined_test[np.where(classes_test==0), 0], combined_test[np.where(classes_test==0), 1], s=10, label='no diabetes')\n",
    "plt.title('Fasting plasma glucose and body mass index in diabetic and healthy patients ')\n",
    "plt.xlabel('Ammount of fasting plasma glucose in blood')\n",
    "plt.ylabel('Weight index')\n",
    "plt.legend()\n",
    "\n",
    "def draw_classifier_class_bound(classifier, X):\n",
    "    \"\"\"\n",
    "    In this function the class boundary of the classifier is drawn on a two-dimensional graph \n",
    "    \"\"\"\n",
    "    x_min, x_max = X[:,0].min(), X[:,0].max()\n",
    "    y_min, y_max = X[:,1].min(), X[:,1].max()\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.2), np.arange(y_min, y_max, 0.1))\n",
    "    Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contour(xx, yy, Z, colors='k', linewidths=0.7)\n",
    "\n",
    "draw_classifier_class_bound(classifier_combined, combined_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a woman from the Pima Indian family who comes to the reception has a body mass index of 25 and a fasting plasma glucose level of 180 mg / dL, what is the probability that the patient has diabetes? Use the two-variable logistic regression classifier classifier_connected. [predict_proba()](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba) function to predict the posterior probabilities of classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data = [[180,25]]\n",
    "#-------- Your code here --------\n",
    "posterior_probability = \n",
    "#-----------------------------------\n",
    "print('The patient has a {}% posterior probability of developing diabetes'.format(round(100*posterior_probability[0][1],2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback\n",
    "Finally answer the following questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How much time did you spent on this exercise?**\n",
    "\n",
    "`Your answer here`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Did you face any problems during this exercise? Was notebook material enough for doing this exercise?**\n",
    "\n",
    "`Your answer here`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other feedback related to this exercise**\n",
    "\n",
    "`Your answer here`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Returning the exercise\n",
    "\n",
    "1. Before you return this notebook **make sure that code in notebook works properly** and returns all necessary values by choosing from menu `Kernel -> Restart & Run All`! also make sure you have answer all questions on **bold**\n",
    "2. Empty all outputs and variables by choosing from menu `Kernel -> Restart & Clear Output`. This step reduces the size of notebook remarkably\n",
    "3. Rename this notebook in following format **`JT_H2_[student_number(s)].ipynb`** (e.g `JT_H2_1234567.ipynb` or if you have group `JT_H2_1234567_2345678_3456789.ipynb`)\n",
    "4. Return **only** solved notebook(`file ending with .ipynb`) to moodle programming exercise 1. Everyone must return file to moodle even if you work in a group. **Don't include working directory or other files** when you return the exercise.\n",
    "5. Finally go answer questions in moodle related to programming exercise 2. Everyone in your group must answer to questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
