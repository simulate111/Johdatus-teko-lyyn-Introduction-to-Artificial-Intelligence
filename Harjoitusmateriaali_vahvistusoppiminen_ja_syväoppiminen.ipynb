{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>521160P Johdatus Tekoälyyn<br><br>Harjoitusmateriaali<br><br>Vahvistusoppiminen ja syväoppiminen<br></center>\n",
    "\n",
    "\n",
    "Vahvistusoppiminen ja syväoppiminen ovat tekoälyn osa-alueita, joilla ratkaistaan usein erityyppisiä ongelmia. Ne voidaan myös yhdistää, kuten eräässä sovelluksessa tehtiin kehittäessä tekoäly Atarin videopeleihin algoritmilla syvä-Q-oppiminen [1]. Käsitellään kuitenkin tässä harjoitusmateriaalissa vahvistusoppimista ja syväoppimista omina osa-alueinaan.\n",
    "\n",
    "## Vahvistusoppiminen\n",
    "\n",
    "Koneoppiminen jaetaan ohjattuun oppimiseen, ohjaamattomaan oppimiseen ja vahvistusoppimiseen. Vahvistusoppimisen lähestymistapa ongelmiin on erilainen kuin dataan ja sen näytteiden lähtömuuttujiin perustuvassa ohjatussa oppimisessa tai datan rakenteisuuteen perustuvassa ohjaamattomassa oppimisessa. Vahvistusoppimisessa oppiminen tapahtuu reaaliaikaisesti tehtyjen yritysten ja erehdysten kautta [2].  Siinä toimija eli **agentti** yrittää löytää parhaan mahdollisen **liikkeen tiloista**, joihin sillä on mahdollista siirtyä agentin toimiessa määrätyssä **toimintaympäristössä**. Agentin valitsemia liikkeitä arvioidaan positiivisten ja negatiivisten **palautteiden** avulla sen mukaan, johtiko liike haluttuun lopputulokseen. Palautteiden arvot tallennetaan tila-liike-taulukkoon päivittämällä aina tutkittavan tila-liike parin arvoa vahvistusoppimismenetelmän päivityssäännöllä. Ajan kuluessa agentti oppii **strategian**, jota noudattamalla se pääsee päämääräänsä optimaalisin liikkein. Kuvassa 1 agentti oppii tiloille parhaat liikkeet toimiessaan määrätyssä toimintaympäristössä.\n",
    "\n",
    "<br>\n",
    "<div style=\"width:image width px; font-size:80%; text-align:center;\">\n",
    "    <center>\n",
    "    <img src='kuvat\\reinforcement.png' width='550' height='auto' style='padding-bottom:0.5em;' />\n",
    "    </center>\n",
    "    <span>Kuva 1. Agentti toimii määrätyssä toimintaympäristössä oppien parhaat liikkeet.</span>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Otetaan yksinkertainen esimerkki vahvistusoppimisesta. Erään risteyksen liikennevalo-ohjaukseen toteutetaan ratkaisu vahvistusoppimisella. Liikennevalo-ohjausjärjestelmä toimii esimerkin agenttina. Agentti saa tiedon autojen lukumäärästä risteyksen eri kaistoilla, jonka perusteella sen on kyettävä päästämään autot sujuvasti risteyksen ohi. Autojen lukumäärät risteyksen kaistoilla eri ajanhetkinä ovat tiloja ja ohjausjärjestelmän tekemät päätökset, kuten mille kaistoille näytetään vihreää valoa ja kuinka kauan, ovat liikkeitä. Agentin toiminnasta eri tilanteissa annetaan palautetta esimerkiksi perustuen autojen odotusaikaan risteyksessä. Esimerkin toimintaympäristön muodostavat kaikki mahdolliset tilat, kuinka paljon autoja voi kertyä risteyksen eri kaistoille ja kaikki mahdolliset liikkeet, jotka agentti voi suorittaa eri tilanteissa. Alussa agentti toimii sattumanvaraisia liikkeitä tehden ja liikenne tulee ruuhkautumaan risteyksen kohdalla. Pitkän ajan kuluttua agentti oppii purkamaan ruuhkan palautteista opittujen tila-liike-taulukon arvojen avulla ja se pystyy muodostamaan strategioita eri tilanteita varten.\n",
    "\n",
    "Agentin oppiessa yrityksiä ja erehdysiä tekemällä strategian, se hyödyntää aiemmin opittua tietoa (engl. exploitation) hyviin palautteisiin johtavien liikkeiden valitsemiseksi. Tämän lisäksi agentilla on mahdollisuus valita huonomman palautteen saaneita liikkeitä tai aivan uusia liikkeitä (engl. exploration) saadakseen kattavampi kuva koko toimintaympäristöstä. Usein opetettaessa agentille strategiaa vuorotellaan näiden kahden liikkeiden valintatavan välillä esimerkiksi valitsemalla yhdeksän kymmenestä kerrasta parhaaksi havaittu liike ja yhden kymmenestä kerrasta sattumanvarainen liike (engl. epsilon-greedy policy).\n",
    "\n",
    "Eri vahvistusoppimismenetelmät hyödyntävät eri ominaisuuksia. Menetelmä voi olla mallivapaa (engl. model-free), jolloin oletetaan, että tilojen ja liikkeiden välillä ei ole riippuvuuksia, eikä menetelmä mallinna tällöin ympäristöään oppimisen aikana. Vastaavasti mallipohjainen (engl. model-based) menetelmä oppii mallin ympäristöstään. Tällöin esimerkiksi agentin tehdessä tilassa $S_{1}$ liikkeen $A_{1}$ ja saaden ympäristöstä uuden tilan $S_{2}$ sekä palautteen $R_{1}$, malli oppii, millä todennäköisyydellä tilasta $S_{1}$ päädytään tilaan $S_{2}$ ja palautteen arvoon $R_{1}$.\n",
    "\n",
    "Vahvistusoppimismenetelmä Monte Carlo-simulaatio on mallivapaa menetelmä, jonka uuden tilan arvon laskemiseksi on odotettava palautetta tapahtuman päätetilaan asti [3]. Päätetila voi olla esimerkiksi yhden Blackjack-korttipelin päättävä siirto tai ajanhetki, kun risteyksen ruuhkatiedosta voidaan antaa uusi palaute autojen ollessa pysähtyneinä. Monte Carlo-simulaatio käyttää yhtälön 1 päivityssääntöä.\n",
    "\n",
    "<br>\n",
    "\\begin{equation}\n",
    "Q(S_{t}, A_{t}) \\leftarrow Q(S_{t}, A_{t}) + \\alpha \\: (R_{t}-Q(S_{t}, A_{t}))\\;, \\tag{1}\n",
    "\\end{equation}\n",
    "<br>\n",
    "\n",
    "*missä $Q(S_{t}, A_{t})$ on tila-liike parin Q-arvo, $R_{t}$ on tila-liike parin saama palautteen arvo ja $\\alpha$ on oppimisnopeus (engl. learning rate), joka kertoo, millä painokertoimella uusi tieto korvaa vanhan tiedon. Oppimisnopeus saa arvoja väliltä $[0,1]$, missä arvolla 0 oppimista ei tapahdu ollenkaan ja arvolla 1 uusi palautteen arvo korvaa täysin aiemman Q-arvon.*\n",
    "\n",
    "Mikäli toimintaympäristö on deterministinen eli se ei muutu ajan kuluessa tai stationäärinen eli ympäristön muuttuessa muutoksen todennäköisyysjakauma on tiedossa, oppimisnopeutena voidaan käyttää arvoa $\\alpha = \\frac{1}{N(S_{t}, A_{t})}$ , missä $N(S_{t}, A_{t})$ kertoo, montako kertaa kyseisessä tila-liike parissa on vierailtu.\n",
    "\n",
    "Otetaan esimerkki Monte Carlo-simulaation toiminnasta. Eräälle tila-liike parille $(S, A)$ saadaan ajan kuluessa palautteiden arvot $R_{t} = [4,3,2,1]$ ja oppimisnopeus $\\alpha$ on $\\frac{1}{2}$. Yhtälöä 1 käyttämällä saadaan laskettua tila-liike parin Q-arvot eri ajan hetkinä.\n",
    "\n",
    "<br>\n",
    "$\\hspace{7.55cm} Q(S, A)=0$<br>\n",
    "$R_{1}=4, \\hspace{6cm}     Q(S, A)= 0 + \\frac{1}{2}(4-0) = 2$<br>\n",
    "$R_{2}=3, \\hspace{6cm}     Q(S, A)= 2 + \\frac{1}{2}(3-2) = \\frac{5}{2}$<br>\n",
    "$R_{3}=2, \\hspace{6cm}     Q(S, A)= \\frac{5}{2} + \\frac{1}{2}(2-\\frac{5}{2}) = \\frac{9}{4}$<br>\n",
    "$R_{4}=1, \\hspace{6cm}     Q(S, A)= \\frac{9}{4} + \\frac{1}{2}(1-\\frac{9}{4}) = \\frac{13}{8}$<br>\n",
    "<br>\n",
    "\n",
    "Toinen erittäin tunnettu vahvistusoppimismenetelmä Q-oppiminen on myös mallivapaa menetelmä, jossa tila-liike parin Q-arvo päivitetään heti tilasta tehdyn liikkeen jälkeen tila-liike-taulukkoon. Palautetta ei siis tarvitse odottaa koko tapahtuman päättymiseen asti. Q-oppiminen käyttää yhtälön 2 päivityssääntöä.\n",
    "\n",
    "<br>\n",
    "\\begin{equation}\n",
    "Q(S_{t},A_{t}) \\leftarrow Q(S_{t},A_{t}) + \\alpha \\: [R_{t} + \\gamma \\max (Q(S_{t+1},A_{t})) - Q(S_{t},A_{t})]\\:, \\tag{2}\n",
    "\\end{equation}\n",
    "<br>\n",
    "\n",
    "*missä $Q(S_{t},A_{t})$ on tila-liike parin Q-arvo, $\\max(Q(S_{t+1},A_{t}))$ on seuraavien tila-liike parien suurin Q-arvo ja γ on ns. vaimennuskerroin (engl. discount factor), joka määrittää, kuinka paljon tulevien palautteiden arvoja vaimennetaan suhteessa välittömästi saatavien palautteiden arvoihin. Vaimennuskerroin saa arvoja väliltä [0,1], missä arvolla 0 agentti on lyhytnäköinen ottaen huomioon ainoastaan liikkeiden seuraavat palautteiden arvot ja arvolla 1 agentti on kauaskatseinen arvottaen kaikki tulevat palautteet saman arvoisiksi.*\n",
    "\n",
    "\n",
    "## Syväoppiminen\n",
    "\n",
    "Syväoppiminen on tällä hetkellä tekoälyn yksi kuumimpia tutkimuskohteita, jonka laskennassa käytettyjen neuroverkkojen kehitystä ovat ajan saatossa innoittaneet ihmisaivojen rakenne ja toiminta. Syväoppimista on tutkittu jo 1960-luvulta lähtien, mutta täydellinen läpimurto saavutettiin vasta 2010-luvulle tultaessa massadatan käytön lisääntymisen, tietokoneiden laskentatehon kasvamisen ja koneoppimismenetelmien kehittymisen myötä. Syväoppimista voidaan soveltaa lähes kaikkiin tekoälyn osa-alueisiin.\n",
    "\n",
    "Keinotekoiset neuroverkot koostuvat ihmisaivojen tapaan neuroneista, jotka ovat yksinkertaisia toisiinsa kytkettyjä tiedonkäsittely-yksiköitä. Biologisen ja keinotekoisen neuronin rakenteet muistuttavat toisiaan kuvan 2 tapaan. Biologisessa neuronissa sen tuojahaarakkeet kuljettavat tiedon sähköisenä impulssina kohti solukeskusta, josta viejähaarake vie käsitellyn tiedon eteenpäin. Vastaavasti keinotekoisessa neuronissa eri painokertoimilla kerrotut syötteet ja bias-termi summataan yhteen summaajassa. Tämän jälkeen summalle lasketaan aktivointifunktiolla, kuten sigmoid-funktiolla tai ReLU-funktiolla (engl. rectified linear unit), epälineaarinen kuvaus [4]. Jos aktivointifunktiona käytetään kynnystystä (engl. threshold), käytetään neuronista nimitystä perceptroni.\n",
    "\n",
    "<br>\n",
    "<div style=\"width:image width px; font-size:80%; text-align:center;\">\n",
    "    <center>\n",
    "    <img src='kuvat\\neurons.png' width='850' height='auto' style='padding-bottom:0.5em;' />\n",
    "    </center>\n",
    "    <span>Kuva 2. Biologisen ja keinotekoisen neuronin rakenteet muistuttavat toisiaan.</span>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Keinotekoisista neuroneista rakennettu monikerrosneuroverkko koostuu syötekerroksesta, lähtökerroksesta sekä niiden välissä olevista piilokerroksista kuvan 3 tapaan. Neuroverkkojen opettaminen tarkoittaa verkossa olevien neuronien painokertoimien säätämistä. Yksittäinen datanäyte tulee sisään syötekerrokselle, josta informaatio etenee piilokerrosten kautta lähtökerrokselle. Kun näytteen lähtömuuttuja on tiedossa, voidaan painokertoimia säätämällä saada se vastaamaan verkon avulla ennustettua lähtömuuttujaa. Tämä tapahtuu vastavirta-algoritmilla (engl. backpropagation) kulkemalla verkossa taaksepäin lähtökerrokselta syötekerrokselle laskemalla kustannusfunktion osittaisderivaatat jokaiselle painokertoimelle. Tämän jälkeen neuroverkon painokertoimia säädetään optimaalisemmiksi osittaisderivaattoja käyttävällä päivityssäännöllä minimoiden ennusteen ja lähtömuuttujan välinen virhetermi.\n",
    "\n",
    "<br>\n",
    "<div style=\"width:image width px; font-size:80%; text-align:center;\">\n",
    "    <center>\n",
    "    <img src='kuvat\\neuralnetwork.png' width='700' height='auto' style='padding-bottom:0.5em;' />\n",
    "    </center>\n",
    "    <span>Kuva 3. Monikerrosneuroverkko koostuu syötekerroksesta, lähtökerroksesta ja piilokerroksista.</span>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Syöttämällä datanäytteet monta kertaa neuroverkon läpi, opitaan lopulta optimaaliset painokertoimet. Mikäli dataa on vähän ja käytetyssä neuroverkossa on paljon neuroneja, on vaarana ylioppiminen. Vastaavasti jos yksinkertaiseen neuroverkkoon syötetään erittäin kompleksista dataa, ei datasta pystytä oppimaan sen kaikkia ominaisuuksia ja tapahtuu alioppiminen.\n",
    "\n",
    "Tarkastellaan seuraavaksi tarkemmin syväoppimisen arkkitehtuuria nimeltä konvoluutioneuroverkot (engl. convolutional neural networks, CNN), joita käytetään yleisimmin kuvien ja videoiden tunnistus- ja luokittelusovelluksissa. Konvoluutioneuroverkot sisältävät mm. konvoluutiokerroksia (engl. convolutional layers), alinäytteistyskerroksia (engl. pooling layers), täysin-kytkettyjä kerroksia (engl. fully-connected layers), neuronien-pudotuskerroksia (engl. drop-out layers) ja normalisointikerroksia [5]. Konvoluutioneuroverkossa matriisimuotoisten syötteiden arvoja, kuten kuvien pikseleiden arvoja, käsitellään aluksi konvoluutiokerroksissa, josta tuotetut piirteet kulkevat neuroverkon läpi lähtökerrokselle.\n",
    "\n",
    "Konvoluutiokerrokset sisältävät painokertoimista koostuvia maskeja. Maskia liikutetaan matriisimuotoisen syötteen jokaisessa kohdassa ja lasketaan konvoluutio-operaatio maskin ja syötteen kohdan välillä. Opettamisen aikana päivitettävien maskien painokertoimien tehtävä on irrottaa syötteestä monipuoliset piirteet. Kuvassa 4 3x3 kokoiselle syötteelle on suoritettu konvoluutio 3x3 kokoisella maskilla, jonka siirtymä x-akselin ja y-akselin suunnassa on yhden yksikön. Alkuperäisen syötteen ympärille on lisätty yksi yksikköä leveä nollarivi (engl. zero-padding), sillä konvoluutio suuremmilla kuin 1x1 kokoisilla maskeilla pienentää lopputuloksen kokoa. Konvoluutiokerroksen tuottamien piirteiden koko lasketaan yhtälöllä 3.\n",
    "\n",
    "<br>\n",
    "<div style=\"width:image width px; font-size:80%; text-align:left;\">\n",
    "    <center>\n",
    "    <img src='kuvat\\convolution.png' width='400' height='auto' style='padding-bottom:0.5em;' />\n",
    "    </center>\n",
    "    <span>Kuva 4. 3x3 kokoisen syötteen (sininen reunus) ympärille on lisätty yksi yksikköä leveä nollarivi. 3x3 kokoisen maskin (punainen reunus) siirtymän ollessa x-akselin ja y-akselin suuntaan yhden yksikön, lopputuloksen koko tulee olemaan 3x3.</span>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\\begin{equation}\n",
    "O =  \\frac{W-F+2P}{S} + 1\\:, \\tag{3}\n",
    "\\end{equation}\n",
    "<br>\n",
    "\n",
    "missä $W$ on syötteen leveys (engl. input width), $F$ on maskin leveys (engl. filter width), $P$ on lisätyn nollarivin leveys (engl. padding), $S$ on siirtymä (engl. stride) ja $O$ on konvoluutiokerroksen tuottaman lopputuloksen leveys (engl. output width).\n",
    "\n",
    "Alinäytteistyskerros sijoitetaan neuroverkossa usein heti konvoluutiokerroksen jälkeen. Alinäytteistyskerros tiivistää informaatiota pienentäen piirteiden spatiaalista kokoa. Tämä puolestaan nopeuttaa laskentaa ja vähentää ylioppimisen riskiä. Maksimiarvo-alinäytteistyksessä (engl. max-pooling) ruudukolla jaettujen alueiden sisältä valitaan suurimmat arvot. Keskiarvo-alinäytteistyksessä (engl. average-pooling) ruudukolla jaettujen alueiden arvoista otetaan keskiarvot. Kuvassa 5 4x4 kokoinen syöte alinäytteistetään vertailun vuoksi 2x2 kokoisella maksimiarvo-alinäytteistyskerroksella ja keskiarvo-alinäytteistyskerroksella.\n",
    "\n",
    "<br>\n",
    "<div style=\"width:image width px; font-size:80%; text-align:center;\">\n",
    "    <center>\n",
    "    <img src='kuvat\\pooling.png' width='400' height='auto' style='padding-bottom:0.5em;' />\n",
    "    </center>\n",
    "    <span>Kuva 5. Alinäytteistys maksimiarvo-alinäytteistyskerroksella ja keskiarvo-alinäytteistyskerroksella.</span>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Kun datan kuvanäytteille on tarkoitus ennustaa mihin luokkaan ne kuuluvat, konvoluutioneuroverkon loppuosa koostuu täysin-kytketyistä kerroksista. Konvoluutiokerrosten ja alinäytteistyskerrosten tuottamat matriisimuotoiset piirteet muunnetaan yksiulotteiseksi listaksi. Listassa olevat numeroarvot syötetään syötekerrokselle, josta ne muunnetaan mahdollisten piilokerrosten kautta ennustetuksi luokkatiedoksi lähtökerroksella.\n",
    "\n",
    "Ylioppiminen on yleinen ongelma konvoluutioneuroverkkoja opetettaessa. Sitä voidaan kontrolloida alinäytteistyskerrosten lisäksi erilaisilla neuronien-pudotuskerroksilla ja normalisointikerroksilla. Neuronien-pudotuskerroksissa opetusvaiheessa osa neuroneista pudotetaan sattumanvaraisesti pois neuroverkosta kuvan 6 tapaan. Yleisin normalisointikerros on normalisointi erän suhteen (engl. batch normalization). Siinä iteraation aikana erän piirteistä vähennetään erän keskiarvo ja jaetaan erän keskihajonnalla. \n",
    "\n",
    "<br>\n",
    "<div style=\"width:image width px; font-size:80%; text-align:center;\">\n",
    "    <center>\n",
    "    <img src='kuvat\\dropout.png' width='450' height='auto' style='padding-bottom:0.5em;' />\n",
    "    </center>\n",
    "    <span>Kuva 6. Vasemmalla puolella on alkuperäinen neuroverkko ja oikealla puolella neuronien pudotuksen jälkeinen neuroverkko.</span>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Erilaisista kerrostyypeistä muodostetaan kokonaisia konvoluutioneuroverkkoja. Kuvassa 7 on erään konvoluutioneuroverkon rakenne, jolla 32x32 pikselin kokoiselle RGB-kuvalle halutaan ennustaa, onko sen luokka koira, kissa vai lintu. Konvoluutioneuroverkko sisältää kolme peräkkäistä konvoluutiokerroksen ja maksimiarvo-alinäytteistyskerroksen muodostamaa lohkoa. Tämän jälkeen kuvasta muunnetut piirteet syötetään täysin-kytketyn kerroksen kautta lähtökerrokselle luokkatiedoksi. Kuvan 7 konvoluutioneuroverkon opettamisen jälkeen verkolla ennustettu testikuva kissasta tunnistetaan 97 prosentin posterioritodennäköisyydellä luokkaan kissa, kahden prosentin posterioritodennäköisyydellä luokkaan koira ja yhden prosentin posterioritodennäköisyydellä luokkaan lintu.\n",
    "\n",
    "<br>\n",
    "<div style=\"width:image width px; font-size:80%; text-align:center;\">\n",
    "    <center>\n",
    "    <img src='kuvat\\network.jpg' width='1100' height='auto' style='padding-bottom:0.5em;' />\n",
    "    </center>\n",
    "    <span>Kuva 7. Eräs 32x32 pikselin kokoisien RGB-kuvien ennustamiseen muodostettu konvoluutioneuroverkko.</span>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "## Lähteet\n",
    "\n",
    "[1]    Mnih V., Kavukcuoglu K., Silver D., Graves A., Antonoglou I., Wierstra D. & Riedmiller M. (2013) Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602.\n",
    "\n",
    "[2]    Sutton R. S. & Barto A. G. (1998) Reinforcement learning: An introduction. MIT press.\n",
    "\n",
    "[3]    Silver D. Reinforcement learning lectures. URL: http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html.\n",
    "\n",
    "[4]    Bishop, C. M. (2006) Pattern recognition and machine learning. Springer Science+ Business Media.\n",
    "\n",
    "[5]    Fei-Fei L. Convolutional Neural Networks for Visual Recognition. URL: https://cs231n.github.io/convolutional-networks/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
